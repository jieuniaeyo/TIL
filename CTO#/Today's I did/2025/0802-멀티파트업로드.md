
## Multipart Upload

---

### 기존 방식

클라이언트에서 데이터를 업로드하면 전체 파일을 한 번에 전송

**기존 방식의 문제점**

- **메모리 소비** → 파일 전체를 메모링함으로써 버퍼링
- **시간 초과** → 대용량 파일의 경우 시간 초과 유발 가능
- **연결 안정성** → 업로드가 길수록 네트워크 문제 발생 가능
- **확장성** → 다수의 사용자가 동시에 대용량 파일을 업로드 할 시 서버의 부하

**chunk 단위 업로드 장점**

- 한 번에 전송하는 데이터의 양을 줄여 서버와의 연결이 끊어지는 것을 방지할 수 있음
- 업로드 진행상황 확인 가능

### 1차 계획

**클라이언트 사이드**

- 파일을 작은 단위의 chunk로 나누어서 전송

**백엔드**

- 전송 받은 chunk들을 하나로 수합해 파일 재생성
- 재생성된 파일을 기반으로 S3 업로드

** 애셔님 피드백 → 네트워크 길이가 길어짐으로 chunk를 바로 S3 업로드 방식 (Java에서는 가능)

[AWS 자료](https://docs.aws.amazon.com/ko_kr/sdk-for-java/latest/developer-guide/best-practices-s3-uploads.html)

### 2차 계획

**클라이언트 사이드**

- 파일을 작은 단위의 chunk로 나누어서 전송

**백엔드**

- 전송 받은 chunk들을 바로 S3 업로드

[AWS 자료](https://docs.aws.amazon.com/AmazonS3/latest/API/API_UploadPart.html)


**CreateMultiPartUpload**

→ 분할 업로드 방식에 사용되는 S3 제공 메서드

→ 하나의 파일을 여러 조각으로 나누어 전송

→ 이론상 5TB까지 업로드가 가능

→ 생성시 반환되는 uploadId를 기반으로 파일 업로드

### 테스트

500mb, 1gb, 3gb의 파일, 동일한 네트워크 환경에서 테스트

![Screenshot 2025-08-02 at 13.26.18.png](attachment:a9f139e1-9baa-424d-b1e4-319804557cad:Screenshot_2025-08-02_at_13.26.18.png)

**약 500MB 파일**

- 멀티파트 업로드 - 23346 (약 23초)

```bash
------ Multipart Upload ------
멀티파트 업로드 시작시간 >  1754107945400
멀티파트 업로드 종료시간 >  1754107968745
멀티파트 업로드 소요시간 >  23346
------ Multipart Upload ------
```

- 단일 업로드 - 29366 (약 29초)

```bash
------ Single Upload ------
단일 업로드 시작시간 >  1754108188291
단일 업로드 종료시간 >  1754108217655
단일 업로드 소요시간 >  29366
------ Single Upload ------
```


**약 1GB 파일**

- 멀티파트 업로드 - 46323 (약 46초)

```bash
------ Multipart Upload ------
멀티파트 업로드 시작시간 >  1754108246015
멀티파트 업로드 종료시간 >  1754108292337
멀티파트 업로드 소요시간 >  46323
------ Multipart Upload ------
```

- 단일 업로드 - 61842 (약 60초)

```bash
------ Single Upload ------
단일 업로드 시작시간 >  1754108382463
단일 업로드 종료시간 >  1754108444304
단일 업로드 소요시간 >  61842
------ Single Upload ------
```


**약 3GB 파일**

- 멀티파트 업로드 - 142404 (약 142초)

```bash
------ Multipart Upload ------
멀티파트 업로드 시작시간 >  1754108867325
멀티파트 업로드 종료시간 >  1754109009727
멀티파트 업로드 소요시간 >  142404
------ Multipart Upload ------
```

- 단일 업로드 - 163361 (약 160초)

```bash
------ Single Upload ------
단일 업로드 시작시간 >  1754108685822
단일 업로드 종료시간 >  1754108849181
단일 업로드 소요시간 >  163361
------ Single Upload ------
```


** 물론 도서관 와이파이를 사용해서 속도가 느린 부분, chunkSize를 5MB 설정하여 여러 번의 API 호출이 있었다는 점을 고려하면 이후 속도가 더 빨라질 가능성 있음

### 추가 작업

다운로드도 마찬가지로 chunk 단위로 나누어서 다운로드

[AWS 자료](https://aws.amazon.com/ko/blogs/korea/amazon-s3-multi-part-dowload/)

** [참고](https://dev.to/mallikarjunht/multipart-download-from-s3-in-java-1hjd)

### 시행착오

**멀티파트 업로드의 속도가 단일 업로드 속도보다 느린 현상**

초기에 테스트를 할 때 500mb 파일도 멀티파트는 30초 대, 단일 업로드는 10초대가 나옴

→ 단일 업로드는 한 번의 API 호출로 끝나지만 멀티파트는 다수의 파트를 나눠 병렬로 업로드 후 정합성 검증이 필요해 상대적으로 더 많은 시간 소요

→ 초기에 병렬 처리가 구현되지 않은 상태에서 직렬로 업로드되면서 오히려 느려짐

**성공 시 느려지는 현상**

업로드가 실패했을 땐 2초 이내로 끝났지만, 성공하자 20초 이상 걸림

→ 실패 시: 일부 청크 업로드 후 중단되기 때문에 빠르게 종료

→ 성공 시: 모든 청크 업로드 + 완료 요청까지 처리되면서 전체 프로세스 소요 시간이 반영

**chunk 업로드 완료 후 parts가 null이 되는 문제**

모든 파트를 정상적으로 업로드해도 `completeMultipartUpload` 단계에서 parts가 누락

→ uploadPart() 실패시 반환값이 없어 Promise.all()이 깨짐

**프론트에서 마지막 chunk 감지 실패**

→ 잘못된 로직으로 인해 마지막 chunk 감지 실패

```tsx
const minRepeat = Math.ceil(file.size / chunkSize);
if (offset === minRepeat) {
formData.append('isLast', 'true');
}
```

→ 이후 문제를 인지하고 수정한 로직

```tsx
const isLast = offset + chunkSize >= file.size;
if (isLast) {
formData.append('isLast', 'true');
}
```

**다운로드시 Node.js Out of Memory 에러 발생**

→ 다운로드 크기를 실수로 5mb * 5mb로 설정

→ 이후 10mb로 수정

**다운로드 성공은 했지만 프론트에서 실제 다운로드를 못 받는 문제**

→ response를 받은 후 별도의 로직을 실행하지 않고 있었음

→ 클라이언트 측에서 Blob 생성, URL a 태그 클릭 등 별도 다운로드 구현으로 다운로드 성공

**버퍼 다운로드 타입 문제**

→ 버퍼를 연결할 때 undefined, string, Blob 등 다양한 데이터가 섞여 있어 에러 발생

→ GPT의 도움을 받아 처리 로직을 추가해 에러 해결

```tsx
if (Buffer.isBuffer(data.Body)) {
return data.Body;
} else if (typeof data.Body === 'string') {
return Buffer.from(data.Body);
} else if ('readable' in data.Body) {
return await this.streamToBuffer(data.Body);
} else {
throw new Error(`지원하지 않는 바디 타입 > ${typeof data.Body}`);
}
```

```tsx
async streamToBuffer(stream: NodeJS.ReadableStream): Promise <Buffer> {
return new Promise((resolve, reject) => {
const chunks: Buffer[] = [];
stream.on('data', chunk => chunks.push(Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk)));
stream.on('error', reject);
stream.on('end', () => resolve(Buffer.concat(chunks)));
});
}
```

### 추가 개선 사항

- 파일 확장자를 붙이지 못함

→ key 자체에 file의 확장자를 붙여 해결

### 궁금했던 점
- 병렬처리로 업로드를 처리할 때 몇 개를 돌리는 게 적절할까?

    서버 성능, 네트워크 속도, API 한도에 따라 다르게 설정<br>
    평균적으로 3개 설정