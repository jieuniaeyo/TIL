# \[처리량과 응답시간\] 커넥션풀, 캐싱

## 응답 시간

`[서버 연결 → 서버로 요청 전송 → /서버 실행/ → 클라이언트로 요청 전송]`
다음 과정을 거치는데 소요된 시간

-   Time To First Byte 응답의 첫 번째 바이트 도착까지 걸린 시간 (ms)
-   Time To Last Byte 응답의 마지막 바이트 도착까지 걸린 시간 (ms)

응답 시간과 사용자의 만족도의 상관관계

응답 시간을 줄인다고 만족도 반드시 증가 X, 하지만 응답 시간이 늘어나면
만족도는 확실히 감소

### 응답 시간에 영향을 주는 요인

-   로직 수행
-   DB 연동
-   외부 API 연동
-   응답 데이터 생성

→ 실제로 API 연동과 DB 연동이 대부분의 응답 시간을 차지

## 처리량 (Transaction Per Second)

단위당 시간 시스템이 처리하는 작업량

\*\* 이때 처리에 초점 즉, 0초에 시작되어 3초에 끝나는 작업이 있다면
3초의 처리량으로 카운트

서버가 처리할 수 있는 TPS를 초과한다면 서버는 초과된 요청을 나중에 처리

→ 이로 인해 초과된 요청을 보낸 사용자는 앞선 요청이 처리될 때까지
대기해야함 = 응답 시간 증가

**해결방법**

-   서버가 처리할 수 있는 요청 수 자체를 늘리기
-   처리 시간 자체를 줄이기

TPS를 늘리기 위해 먼저 해야 할 작업은 병목 지점 찾기

### 수직 확장

서버의 자원(CPU, 메모리, 디스크 등)을 증가시키는 방식

→ 즉각적인 효과를 얻을 수 있지만, 트래픽이 증가하면 결국 성능 문제가
다시 발생

서버가 다운되지 않도록 임시로 유지하면서, 그 시간 동안 근본적인 해결
방안을 찾는 용도로 활용

### 수평 확장

서버의 개수를 늘리는 방식

→ DB에 병목이 있다면 수평 확장 시 오히려 DB 부하가 증가할 수 있음

따라서, 병목 지점을 정확히 파악하는 것이 중요

외부 API나 DB 성능이 문제라면 수평 확장 시 각 요소에 더 많은 트래픽이
집중되어 TPS 향상 효과가 없음

## DB 커넥션 풀

DB 사용 시

1.  DB 연결
2.  쿼리 실행
3.  사용이 끝날 시 DB 연결 종료

보통 DB 연결 시 및 종료에 0.5초 \~ 1초의 시간 소요

만약 10ms의 쿼리를 실행하고 DB 연결 및 종료에 50ms가 소요된다면 전체
시간의 80%가 소요

### 커넥션 풀

커넥션들을 미리 생성해 보관 → DB 사용 시 커넥션을 가져와 사용하고 다시
풀에 반환 (재사용)

**주요 설정**

-   커넥션 풀 크기
-   커넥션 대기 시간
-   커넥션 유지 시간

### 커넥션 풀 크기

커넥션 풀에 미리 생성해둘 커넥션 개수 설정

-   최소 커넥션 수 (Minimum Pool Size): 풀에 항상 유지할 최소 커넥션
    개수
-   최대 커넥션 수 (Maximum Pool Size): 풀에서 생성할 수 있는 최대
    커넥션 개수

```{=html}
<!-- -->
```
    if) 커넥션 풀 크기 → 5
            쿼리 실행 → 0.1
    →   1초에 50개의 요청 처리 가능

    if) 커넥션 풀 크기 → 5
            쿼리 실행 → 0.5
    →   1초에 10개의 요청 처리 가능 

따라서 쿼리 실행에 걸리는 시간에 따라 적절한 크기를 설정해야 함

최소/최대 커넥션 수 설정을 통해 트래픽에 따라 커넥션 개수를 필요한 만큼
유지 가능

\*\* DB 부하가 큰 상황에서 커넥션 개수를 늘리면 오히려 쿼리 실행 시간이
증가될 수 있음

### 커넥션 대기 시간

풀에 사용할 수 있는 커넥션이 없을 때 대기할 수 있는 최대 시간 (보통
0.5초 \~ 3초 이내 설정)

-   커넥션 대기 시간 (Connection Timeout): 사용 가능한 커넥션이 없을 때
    대기하는 최대 시간

```{=html}
<!-- -->
```
    if) 커넥션 풀 크기 → 10
            쿼리 실행 → 10초
            요청 → 20개
            대기 시간 → 30초
    →   10개의 요청이 대기 상태 → 에러 응답이 없어 대기 중인 사용자가 재시도 → 동시 요청 수 30개

    if) 커넥션 풀 크기 → 10
            쿼리 실행 → 10초
            요청 → 20개
            대기 시간 → 5초
    →   10개의 요청이 대기 상태 → 5초 후 에러 응답을 받음 → 동시 요청 수 10개

대기 시간 동안 사용자가 재요청을 할 시 기존 요청 취소 X 신규로 요청이
들어옴

→ 즉, 에러 응답이 나오지 않아 사용자가 새로고침을 한다면 동시 요청 수가
계속해서 증가

### 커넥션 유지 시간

커넥션이 사용되지 않는 시간이 길어지면 연결 종료

-   유휴 커넥션 타임아웃 (Idle Timeout): 사용되지 않는 커넥션을 풀에서
    제거하기까지의 시간

→ DB 설정 비활성화 유지 시간보다 짧을 시 DB가 연결을 끊기 전 커넥션에서
먼저 제거 가능

-   유효성 검사 (Validation Query): 커넥션이 정상적으로 사용 가능한
    상태인지 확인

→ 커넥션을 가져올 때 유효성을 검사하거나 주기적으로 검사 가능

-   커넥션 최대 수명 (Max Lifetime): 커넥션이 생성된 후 풀에서 유지되는
    최대 시간

→ 커넥션이 유효하더라도 최대 수명이 지나면 풀에서 제거

\*\* 최대 유휴 시간 / 유지 시간 무한대로 설정 지양

## 캐시

동일한 데이터를 요청할 때 DB가 아닌 캐시에서 데이터를 읽어와 응답 (자주
조회되는 데이터 저장 적합)

### 적중률

캐시가 얼마나 효율적으로 사용되는 지 판단

    캐시에 존재하는 데이터의 개수 / 캐시에서 조회를 시도한 횟수

적중률이 높을 수록 DB 연동 감소, 응답 시간 감소, DB 부하 감소로 이어짐

하지만 캐시 메모리 용량에는 한계가 있기 때문에 기존 데이터들을 제거해야
함

**캐시 삭제 규칙**

-   Least Recently Used: 가장 오래전 사용된 데이터 제거
-   Least Frequently Used: 가장 적게 사용된 데이터 유지
-   First In First Out: 가장 먼저 들어온 데이터 제거

### 로컬 캐시 vs 리모트 캐시

**로컬 캐시**

장점 - 속도가 빠름 (서버 프로세스와 동일한 메모리를 사용하기 때문에)

단점 - 데이터 크기에 제한, 서버 프로세스 재시작 시 캐시 삭제

**리모트 캐시**

장점 - 캐시 크기 확장 가능, 서버 프로세스가 재시작 되더라도 캐시 유지

단점 - 속도가 느림 (네트워크 통신이 필요하기 때문에 로컬에 비해
상대적으로 느림)

\*\* 데이터 규모가 작고 변경 빈도가 잦다면 로컬 캐시 적합

\*\* 데이터 규모가 크고 배포 빈도가 잦다면 리모트 캐시 적합

**사전 적재**

트래픽이 특정 순간에 급증하는 패턴을 보인다면 미리 캐시에 저장하는 방향
고려 필요

    if) 사용자가 500만 명인 앱에서 특정 쿠폰 발급 → 당일 10%의 사용자가 접속해도 트래픽 100만
    → 미리 500만개의 데이터를 캐시에 저장해두면 당일 10%의 사용자가 접속해도 적중률 99% 이상 유지 가능

**캐시 무효화**

유효하지 않는 데이터를 적절한 시점에 캐시에서 삭제하는 것

-   민감한 데이터 → 원본 데이터 변경시 즉시 캐시 무효화, 리모트 캐시
    저장 (다른 서버 로컬 캐시 변경 X)
-   일반 데이터 → 유효시간을 설정해 주기적으로 갱신

**가비지 컬렉터 / 메모리 사용**

사용하지 않는 메모리를 찾아 반환 → 자바의 경우 가비지 컬렉터가 실행되는
동안 모든 실행 일시 중단

\*\* 메모리 사용량과 GC 시간은 비례 (실제 메모리 사용 패턴에 맞게 최대
힙 크기 조절)

대량 객체 생성 시 메모리 부족 상태 지속 → 데이터 개수 / 조회 범위를
트래픽 규모와 메모리 크기에 맞춰 제한

\*\* 파일 다운로드와 같은 기능 구현 시 스트림을 사용하면 한 번에 읽는
것에 비해 메모리 절약 가능

# [처리량과 응답시간] 응답 데이터 압축

응답시간에는 데이터 전송 시간도 포함

**영향 요인**

- 네트워크 속도
- **데이터 크기 → 응답하는 데이터를 압축해 전송하면 전송 시간을 줄일 수 있음**

**고려 사항**

- 데이터 압축 시 텍스트 형식의 데이터는 압축률이 높아 효과적, 이미 압축된 데이터들은 압축률이 낮아 효과 X
- 응답 데이터가 압축되지 않았다면 방화벽이 해제했을 수 있어 확인 필요

## 정적 자원

정적 자원 로드는 전체 트래픽의 상당 부분을 차지 → 실제 동작과 무관하게 불필요한 트래픽 차지

### 클라이언트 캐시 사용

Cache-Control 헤더를 사용해 응답 데이터를 전송하게 되면 설정된 시간만큼 서버 요청 X 캐시 데이터 사용

단, 클라이언트 캐시는 브라우저 단위로 작동 → 즉, 특정 시간대에 다수의 신규 사용자가 접속시 트래픽 증가

### CDN 사용 (Content Delivery Network)

콘텐츠 전송을 위한 별도의 네트워크 사용

**동작 방식**

1. CDN url을 통해 콘텐츠 접근
2. 만약 CDN이 해당 콘텐츠를 가지고 있지 않다면 오리진 서버에서 읽어와 제공
3. 해당 콘텐츠는 CDN에 캐시
4. 이후 같은 콘텐츠에 대한 요청이 들어오면 CDN에서 처리

→ 동일한 콘텐츠에 대해 여러번 요청이 들어와도 서버에서는 최초 한 번만 담당

** CDN은 여러 지역에 서버를 두어 가까운 곳에서 더 빠르게 콘텐츠 응답이 가능

## 대기 처리

티켓팅과 같이 짧은 시간 동안 폭증하는 트래픽

**해결 방법**

- 서버 / DB 증설
    
    → 증설된 서버는 줄일 수 있지만, DB는 X 즉, 특정 트래픽을 막기 위해 DB 고정 비용 증가
    
- 수용할 수 있는 인원 수 자체를 축소
    
    → 대량의 트래픽 전체를 처리하자 X 수용이 가능한 트래픽만 받고 나머지는 대기처리하자 O
    
    → 서버 증설하지 않고 안정적 트래픽 제공 가능, 사용자의 새로고침으로 인한 트래픽 폭증 방지


# [DB 설계 쿼리] 조회 성능 개선, 주의 사항

## 성능 개선 방법

### 미리 집계

게시글 좋아요 카운트

`select count() from like where id = @` count나 sum 같은 집계 함수는 실행 시간이 오래 걸림

게시글 테이블에 like_count 컬럼을 추가하고, 좋아요 발생 시 ±1 연산으로 미리 집계

### ID 기준 목록 조회 사용

10만 번째 게시글부터 10개 조회

`limit 10 offset 99990` → 99991번째부터 조회하는 것이 아니라, 99990개를 센 후 나머지 10개를 조회하므로 실행 시간이 오래 걸림

`where id > 99990 limit 10` → 99991번째부터 바로 조회 가능

### 조회 범위 제한

특정 사용자 게시글 조회

특정 사용자가 작성한 게시글 전체 조회 → 실행 시간이 오래 걸림

최근 3개월 또는 6개월로 범위를 제한해서 조회 → 최신 데이터 위주로 조회하면 DB 성능 향상, 캐싱 적중률 증가

### 전체 개수 카운트 지양

인덱스를 사용해도 전체 스캔이 발생하고, 인덱스를 사용하지 않으면 실제 데이터를 전부 스캔

따라서 전체 개수를 표시하는 방식은 지양

### 오래된 데이터 삭제 및 분리

데이터 개수와 쿼리 실행 시간은 비례

일정 수준 이상 쌓인 데이터는 삭제하거나 별도로 분리

### DB 장비 확장

DB 부하로 인한 성능 문제 발생 시 → 수직 확장으로 서비스 안정화 및 개선 시간 확보

클라우드 사용 시 DB 성능 향상이 용이

DB 수평 확장 시 처리 가능한 트래픽 증가 (주 DB + 복제 DB 구조)

### 별도 캐시 서버 구축

동일한 데이터 요청으로 인한 DB 부하를 줄이기 위해 별도의 캐시 서버 구축

DB 확장보다 Redis와 같은 캐시 서버 구성이 비용 부담이 적음

## 주의 사항

### 쿼리 타임아웃

트래픽이 증가 해 쿼리 실행 시간이 1초에서 5초가 되었다고 가정

쿼리 타임아웃을 두지 않으면 대기중인 사용자의 재시도로 인해 서버 부하 폭증 가능

타임아웃을 3초로 설정 시 사용자는 에러를 보지만 서버 입장에서는 요청이 정상 종료 → 서버 부하를 줄일 수 있음

### 상태 변경 기능 조회는 복제 DB에서 하지 않기

주 DB에서 복제 DB는 순간적으로 데이터가 일치하지 않을 수 있음

→ 주 DB에서 상태 변경 후 복제 DB 반영까지 시간이 걸릴 수 있음 (트랜잭션 커밋 시점에 이루어짐)

따라서, 상태 변경에 대한 데이터 조회는 주 DB에서 실행

### 배치 쿼리 실행 시간 증가

데이터의 증가로 집계 배치 쿼리의 실행시간이 증가했을 떄 해결책

- 커버링 인덱스 사용 → 집계 시 사용되는 데이터 인덱스를 설계 해 전체 데이터를 스캔하지 않도록 조절
- 데이터 분할 → 특정 시간 별로 데이터를 분할 해 실행 시 작업 시간을 일정 수준 유지할 수 있음

### 타입이 다른 컬럼간 조인

타입이 다른 컬럼 간 조인 시 인덱스의 온전한 사용이 불가

따라서 비교 대상 컬럼의 타입을 맞추어 쿼리 실행 중 발생하는 불필요한 타입 변화 감소

### 테이블 변경은 신중하게

신중하지 못한 테이블 변경은 서비스의 장애로 이어질 수 있음

→ DB는 테이블 변경 시 새 테이블 생성 → 데이터 복사 → 새 테이블 교체 (복사 시간 동안 서비스 정지)

### DB 최대 연결 개수

API 서버 수평 확장 후 DB 연결이 안 되는 경우 → DB 최대 연결 수 확인 필요

** DB 서버 CPU의 사용률이 70% 이상일 경우 DB 부하/성능 저하로 이어질 수 있기 때문에 연결 개수 늘리기 X

# [외부 API 연동] 외부 연동 문제 해결

외부 API 연동 시 연동하는 서비스의 장애는 사용하는 서비스의 장애로 이어짐

## 타임아웃

응답이 나오기까지 대기할 수 있는 시간 설정

```
1. A 서비스의 풀 크기 200
2. 100명의 사용자가 A 서비스에 요청
3. 100개의 요청 처리 가능하기 때문에 처리 시작 / 호출하는 B 서비스에서 응답 X
4. 대기 중인 사용자가 100명 추가 → 동시요청 개수 증가
```

타임아웃을 5초로 걸어주게 되면 B 서비스의 응답을 5초 기다렸다가 에러 응답

→ A 서비스는 들어온 요청들을 처리한 것으로 판단, 따라서 대기 중인 요청을 처리 완료할 수 있음

→ 무한 대기보다는 에러 화면이 더 나음

### 연결 타임아웃

네트워크 연결 시간이 오래 걸리면 대기시간이 증가 → 연결 타임아웃 (3~5초)

### 읽기 타임아웃

연결이 된 후 응답을 받기까지 오래 걸리면 대기시간이 증가 → 읽기 타임아웃 (5~30초)

** 타임아웃 시간이 너무 짧으면 연동 서비스가 처리를 성공해도 타임아웃 에러 발생 가능

## 재시도

외부 연동 시 간헐적으로 연결이 실패하거나 응답이 느려질 수 있음

**조건**

- 단순 조회
- 연결 타임아웃
- 멱등성(연산을 여러 번 적용해도 결과 변화 X)을 가진 변경 기능

** 좋아요와 같이 멱등성이 보장되는 경우에는 재시도 가능

** 포인트 차감 시스템에서 읽기 타임아웃이 났다고 재시도 하게 되면 두 번 차감됨으로 재시도 불가능

**설정**

- 재시도 횟수 → 재시도 횟수만큼 응답 시간 증가하기 때문에 일시적인지, 근본적인지 파악 필요
- 재시도 간격 → 재시도 간격을 점진적으로 늘리는 방식으로 연동 서버 부하 감소

** 재시도 시 연동 서비스는 같은 요청을 두 배로 받게 됨으로 연동 서비스의 성능 상황 고려 필요

## 동시 요청 제한

연동 서비스에 임계치 이상의 요청을 보내게 되면 성능 저하 → 요청을 일정 수준만 보내기

```
1. 연동 서비스가 동시에 처리 가능한 요청이 100개
2. A 서비스에 동시에 300개의 요청이 들어옴
3. 연동 서비스에 100개의 요청만 전달 / 남음 200개의 요청은 503 서버 부하 에러 처리
```

## 서킷 브레이커

연동 서비스가 장애 상황일 때 연동 대신 에러를 응답하고, 정상화되었을 때 연동 재개하는 방식

**상태**

- 닫힘 → 닫힘 상태로 시작, 모든 요청을 연동 서비스에 전달
- 열림 → 실패 건수가 임계치 초과시 열림, 연동 요청 수행 X 에러 응답
    
    → 시간 기준 오류 발생 비율 / 개수 기준 오류 발생 비율
    
- 반 열림 → 열림 상태에서 일정 시간 후 반 열림, 연동 성공 시 닫힘 / 실패 시 열림

https://blog.hwahae.co.kr/all/tech/14541

## 외부 연동과 DB 연동

DB 연동과 외부 연동을 같이 사용할 경우에는 에러 시 DB 트랜잭션을 어떻게 처리할 지 판단 필요

### 외부 연동에 실패했을 때 트랜잭션 롤백

변경된 데이터가 DB에 반영되지 않아 DB 데이터 이상을 방지할 수 있음

하지만, 외부 연동 실패가 읽기 타임아웃일 경우 성공 가능성도 염두해야 함

**트랜잭션 롤백, 하지만 외부 서비스가 실제 성공했을 때 선택할 수 있는 방법**

- 주기적으로 두 시스템 데이터가 일치하는지 확인하고 보정
- 성공 확인 API 호출
- 읽기 타임아웃 발생 시 취소 API 호출

** 성공/취소 API 호출은 외부 서비스가 지원할 때만 가능, 주기적 확인 및 보정 방식이 적합

### 외부 연동 성공했지만 DB 연동 실패했을 때 롤백

취소 API 호출 필요

취소 API가 없거나 취소가 실패할 수도 있기 때문에 주기적으로 데이터 확인 및 보정 작업 지향

### DB 커넥션 풀 문제

만약 DB 쿼리는 0.1초가 걸리지만 외부 연동이 5초 걸리는 상황인 경우

DB 연동과 무관하게 외부 연동을 할 수 있다면 DB 커넥션 전이나 후에 외부 연동 시도 방안 고려 가능

→ 외부 연동이 트랜잭션 밖에서 실행되기 때문에 커밋 이후 롤백이 불가능, 후처리 방안 필요

→ 트랜잭션으로 반영된 데이터를 되돌리는 보상 트랜잭션 등 후처리 방안 …

## HTTP 커넥션 풀

커넥션들을 미리 생성해 보관 → HTTP 연결도 커넥션 풀을 사용하면 연결 시간을 줄일 수 있음

**고려 사항**

- HTTP 커넥션 풀 크기 → 연동 서비스 성능을 고려해 크기 조절 필요 (무분별한 확장은 전체적인 시간 증가)
- 풀에서 HTTP 커넥션을 가져올 떄까지 대기하는 시간 → 대기 시간과 응답 시간은 비례, 짧게 설정 지향
- HTTP 커넥션을 유지할 시간 → 클라이언트 커넥션 풀이 HTTP 커넥션 풀보다 더 오래 유지하면 안 됨
    
    → 죽은 커넥션을 사용할 수도 있음
    

## 연동 서비스 이중화

연동 서비스의 한 곳에 장애가 나도 다른 연동 서비스에서 처리가 가능하도록 이중화

**조건**

- 해당 기능이 서비스의 핵심인가?
- 이중화 비용이 감당 가능한 수준인가?
