# \[처리량과 응답시간\] 커넥션풀, 캐싱

## 응답 시간

`[서버 연결 → 서버로 요청 전송 → /서버 실행/ → 클라이언트로 요청 전송]`
다음 과정을 거치는데 소요된 시간

-   Time To First Byte 응답의 첫 번째 바이트 도착까지 걸린 시간 (ms)
-   Time To Last Byte 응답의 마지막 바이트 도착까지 걸린 시간 (ms)

응답 시간과 사용자의 만족도의 상관관계

응답 시간을 줄인다고 만족도 반드시 증가 X, 하지만 응답 시간이 늘어나면
만족도는 확실히 감소

### 응답 시간에 영향을 주는 요인

-   로직 수행
-   DB 연동
-   외부 API 연동
-   응답 데이터 생성

→ 실제로 API 연동과 DB 연동이 대부분의 응답 시간을 차지

## 처리량 (Transaction Per Second)

단위당 시간 시스템이 처리하는 작업량

\*\* 이때 처리에 초점 즉, 0초에 시작되어 3초에 끝나는 작업이 있다면
3초의 처리량으로 카운트

서버가 처리할 수 있는 TPS를 초과한다면 서버는 초과된 요청을 나중에 처리

→ 이로 인해 초과된 요청을 보낸 사용자는 앞선 요청이 처리될 때까지
대기해야함 = 응답 시간 증가

**해결방법**

-   서버가 처리할 수 있는 요청 수 자체를 늘리기
-   처리 시간 자체를 줄이기

TPS를 늘리기 위해 먼저 해야 할 작업은 병목 지점 찾기

### 수직 확장

서버의 자원(CPU, 메모리, 디스크 등)을 증가시키는 방식

→ 즉각적인 효과를 얻을 수 있지만, 트래픽이 증가하면 결국 성능 문제가
다시 발생

서버가 다운되지 않도록 임시로 유지하면서, 그 시간 동안 근본적인 해결
방안을 찾는 용도로 활용

### 수평 확장

서버의 개수를 늘리는 방식

→ DB에 병목이 있다면 수평 확장 시 오히려 DB 부하가 증가할 수 있음

따라서, 병목 지점을 정확히 파악하는 것이 중요

외부 API나 DB 성능이 문제라면 수평 확장 시 각 요소에 더 많은 트래픽이
집중되어 TPS 향상 효과가 없음

## DB 커넥션 풀

DB 사용 시

1.  DB 연결
2.  쿼리 실행
3.  사용이 끝날 시 DB 연결 종료

보통 DB 연결 시 및 종료에 0.5초 \~ 1초의 시간 소요

만약 10ms의 쿼리를 실행하고 DB 연결 및 종료에 50ms가 소요된다면 전체
시간의 80%가 소요

### 커넥션 풀

커넥션들을 미리 생성해 보관 → DB 사용 시 커넥션을 가져와 사용하고 다시
풀에 반환 (재사용)

**주요 설정**

-   커넥션 풀 크기
-   커넥션 대기 시간
-   커넥션 유지 시간

### 커넥션 풀 크기

커넥션 풀에 미리 생성해둘 커넥션 개수 설정

-   최소 커넥션 수 (Minimum Pool Size): 풀에 항상 유지할 최소 커넥션
    개수
-   최대 커넥션 수 (Maximum Pool Size): 풀에서 생성할 수 있는 최대
    커넥션 개수

```{=html}
<!-- -->
```
    if) 커넥션 풀 크기 → 5
            쿼리 실행 → 0.1
    →   1초에 50개의 요청 처리 가능

    if) 커넥션 풀 크기 → 5
            쿼리 실행 → 0.5
    →   1초에 10개의 요청 처리 가능 

따라서 쿼리 실행에 걸리는 시간에 따라 적절한 크기를 설정해야 함

최소/최대 커넥션 수 설정을 통해 트래픽에 따라 커넥션 개수를 필요한 만큼
유지 가능

\*\* DB 부하가 큰 상황에서 커넥션 개수를 늘리면 오히려 쿼리 실행 시간이
증가될 수 있음

### 커넥션 대기 시간

풀에 사용할 수 있는 커넥션이 없을 때 대기할 수 있는 최대 시간 (보통
0.5초 \~ 3초 이내 설정)

-   커넥션 대기 시간 (Connection Timeout): 사용 가능한 커넥션이 없을 때
    대기하는 최대 시간

```{=html}
<!-- -->
```
    if) 커넥션 풀 크기 → 10
            쿼리 실행 → 10초
            요청 → 20개
            대기 시간 → 30초
    →   10개의 요청이 대기 상태 → 에러 응답이 없어 대기 중인 사용자가 재시도 → 동시 요청 수 30개

    if) 커넥션 풀 크기 → 10
            쿼리 실행 → 10초
            요청 → 20개
            대기 시간 → 5초
    →   10개의 요청이 대기 상태 → 5초 후 에러 응답을 받음 → 동시 요청 수 10개

대기 시간 동안 사용자가 재요청을 할 시 기존 요청 취소 X 신규로 요청이
들어옴

→ 즉, 에러 응답이 나오지 않아 사용자가 새로고침을 한다면 동시 요청 수가
계속해서 증가

### 커넥션 유지 시간

커넥션이 사용되지 않는 시간이 길어지면 연결 종료

-   유휴 커넥션 타임아웃 (Idle Timeout): 사용되지 않는 커넥션을 풀에서
    제거하기까지의 시간

→ DB 설정 비활성화 유지 시간보다 짧을 시 DB가 연결을 끊기 전 커넥션에서
먼저 제거 가능

-   유효성 검사 (Validation Query): 커넥션이 정상적으로 사용 가능한
    상태인지 확인

→ 커넥션을 가져올 때 유효성을 검사하거나 주기적으로 검사 가능

-   커넥션 최대 수명 (Max Lifetime): 커넥션이 생성된 후 풀에서 유지되는
    최대 시간

→ 커넥션이 유효하더라도 최대 수명이 지나면 풀에서 제거

\*\* 최대 유휴 시간 / 유지 시간 무한대로 설정 지양

## 캐시

동일한 데이터를 요청할 때 DB가 아닌 캐시에서 데이터를 읽어와 응답 (자주
조회되는 데이터 저장 적합)

### 적중률

캐시가 얼마나 효율적으로 사용되는 지 판단

    캐시에 존재하는 데이터의 개수 / 캐시에서 조회를 시도한 횟수

적중률이 높을 수록 DB 연동 감소, 응답 시간 감소, DB 부하 감소로 이어짐

하지만 캐시 메모리 용량에는 한계가 있기 때문에 기존 데이터들을 제거해야
함

**캐시 삭제 규칙**

-   Least Recently Used: 가장 오래전 사용된 데이터 제거
-   Least Frequently Used: 가장 적게 사용된 데이터 유지
-   First In First Out: 가장 먼저 들어온 데이터 제거

### 로컬 캐시 vs 리모트 캐시

**로컬 캐시**

장점 - 속도가 빠름 (서버 프로세스와 동일한 메모리를 사용하기 때문에)

단점 - 데이터 크기에 제한, 서버 프로세스 재시작 시 캐시 삭제

**리모트 캐시**

장점 - 캐시 크기 확장 가능, 서버 프로세스가 재시작 되더라도 캐시 유지

단점 - 속도가 느림 (네트워크 통신이 필요하기 때문에 로컬에 비해
상대적으로 느림)

\*\* 데이터 규모가 작고 변경 빈도가 잦다면 로컬 캐시 적합

\*\* 데이터 규모가 크고 배포 빈도가 잦다면 리모트 캐시 적합

**사전 적재**

트래픽이 특정 순간에 급증하는 패턴을 보인다면 미리 캐시에 저장하는 방향
고려 필요

    if) 사용자가 500만 명인 앱에서 특정 쿠폰 발급 → 당일 10%의 사용자가 접속해도 트래픽 100만
    → 미리 500만개의 데이터를 캐시에 저장해두면 당일 10%의 사용자가 접속해도 적중률 99% 이상 유지 가능

**캐시 무효화**

유효하지 않는 데이터를 적절한 시점에 캐시에서 삭제하는 것

-   민감한 데이터 → 원본 데이터 변경시 즉시 캐시 무효화, 리모트 캐시
    저장 (다른 서버 로컬 캐시 변경 X)
-   일반 데이터 → 유효시간을 설정해 주기적으로 갱신

**가비지 컬렉터 / 메모리 사용**

사용하지 않는 메모리를 찾아 반환 → 자바의 경우 가비지 컬렉터가 실행되는
동안 모든 실행 일시 중단

\*\* 메모리 사용량과 GC 시간은 비례 (실제 메모리 사용 패턴에 맞게 최대
힙 크기 조절)

대량 객체 생성 시 메모리 부족 상태 지속 → 데이터 개수 / 조회 범위를
트래픽 규모와 메모리 크기에 맞춰 제한

\*\* 파일 다운로드와 같은 기능 구현 시 스트림을 사용하면 한 번에 읽는
것에 비해 메모리 절약 가능

# [처리량과 응답시간] 응답 데이터 압축

응답시간에는 데이터 전송 시간도 포함

**영향 요인**

- 네트워크 속도
- **데이터 크기 → 응답하는 데이터를 압축해 전송하면 전송 시간을 줄일 수 있음**

**고려 사항**

- 데이터 압축 시 텍스트 형식의 데이터는 압축률이 높아 효과적, 이미 압축된 데이터들은 압축률이 낮아 효과 X
- 응답 데이터가 압축되지 않았다면 방화벽이 해제했을 수 있어 확인 필요

## 정적 자원

정적 자원 로드는 전체 트래픽의 상당 부분을 차지 → 실제 동작과 무관하게 불필요한 트래픽 차지

### 클라이언트 캐시 사용

Cache-Control 헤더를 사용해 응답 데이터를 전송하게 되면 설정된 시간만큼 서버 요청 X 캐시 데이터 사용

단, 클라이언트 캐시는 브라우저 단위로 작동 → 즉, 특정 시간대에 다수의 신규 사용자가 접속시 트래픽 증가

### CDN 사용 (Content Delivery Network)

콘텐츠 전송을 위한 별도의 네트워크 사용

**동작 방식**

1. CDN url을 통해 콘텐츠 접근
2. 만약 CDN이 해당 콘텐츠를 가지고 있지 않다면 오리진 서버에서 읽어와 제공
3. 해당 콘텐츠는 CDN에 캐시
4. 이후 같은 콘텐츠에 대한 요청이 들어오면 CDN에서 처리

→ 동일한 콘텐츠에 대해 여러번 요청이 들어와도 서버에서는 최초 한 번만 담당

** CDN은 여러 지역에 서버를 두어 가까운 곳에서 더 빠르게 콘텐츠 응답이 가능

## 대기 처리

티켓팅과 같이 짧은 시간 동안 폭증하는 트래픽

**해결 방법**

- 서버 / DB 증설
    
    → 증설된 서버는 줄일 수 있지만, DB는 X 즉, 특정 트래픽을 막기 위해 DB 고정 비용 증가
    
- 수용할 수 있는 인원 수 자체를 축소
    
    → 대량의 트래픽 전체를 처리하자 X 수용이 가능한 트래픽만 받고 나머지는 대기처리하자 O
    
    → 서버 증설하지 않고 안정적 트래픽 제공 가능, 사용자의 새로고침으로 인한 트래픽 폭증 방지


# [DB 설계 쿼리] 조회 성능 개선, 주의 사항

## 성능 개선 방법

### 미리 집계

게시글 좋아요 카운트

`select count() from like where id = @` count나 sum 같은 집계 함수는 실행 시간이 오래 걸림

게시글 테이블에 like_count 컬럼을 추가하고, 좋아요 발생 시 ±1 연산으로 미리 집계

### ID 기준 목록 조회 사용

10만 번째 게시글부터 10개 조회

`limit 10 offset 99990` → 99991번째부터 조회하는 것이 아니라, 99990개를 센 후 나머지 10개를 조회하므로 실행 시간이 오래 걸림

`where id > 99990 limit 10` → 99991번째부터 바로 조회 가능

### 조회 범위 제한

특정 사용자 게시글 조회

특정 사용자가 작성한 게시글 전체 조회 → 실행 시간이 오래 걸림

최근 3개월 또는 6개월로 범위를 제한해서 조회 → 최신 데이터 위주로 조회하면 DB 성능 향상, 캐싱 적중률 증가

### 전체 개수 카운트 지양

인덱스를 사용해도 전체 스캔이 발생하고, 인덱스를 사용하지 않으면 실제 데이터를 전부 스캔

따라서 전체 개수를 표시하는 방식은 지양

### 오래된 데이터 삭제 및 분리

데이터 개수와 쿼리 실행 시간은 비례

일정 수준 이상 쌓인 데이터는 삭제하거나 별도로 분리

### DB 장비 확장

DB 부하로 인한 성능 문제 발생 시 → 수직 확장으로 서비스 안정화 및 개선 시간 확보

클라우드 사용 시 DB 성능 향상이 용이

DB 수평 확장 시 처리 가능한 트래픽 증가 (주 DB + 복제 DB 구조)

### 별도 캐시 서버 구축

동일한 데이터 요청으로 인한 DB 부하를 줄이기 위해 별도의 캐시 서버 구축

DB 확장보다 Redis와 같은 캐시 서버 구성이 비용 부담이 적음

## 주의 사항

### 쿼리 타임아웃

트래픽이 증가 해 쿼리 실행 시간이 1초에서 5초가 되었다고 가정

쿼리 타임아웃을 두지 않으면 대기중인 사용자의 재시도로 인해 서버 부하 폭증 가능

타임아웃을 3초로 설정 시 사용자는 에러를 보지만 서버 입장에서는 요청이 정상 종료 → 서버 부하를 줄일 수 있음

### 상태 변경 기능 조회는 복제 DB에서 하지 않기

주 DB에서 복제 DB는 순간적으로 데이터가 일치하지 않을 수 있음

→ 주 DB에서 상태 변경 후 복제 DB 반영까지 시간이 걸릴 수 있음 (트랜잭션 커밋 시점에 이루어짐)

따라서, 상태 변경에 대한 데이터 조회는 주 DB에서 실행

### 배치 쿼리 실행 시간 증가

데이터의 증가로 집계 배치 쿼리의 실행시간이 증가했을 떄 해결책

- 커버링 인덱스 사용 → 집계 시 사용되는 데이터 인덱스를 설계 해 전체 데이터를 스캔하지 않도록 조절
- 데이터 분할 → 특정 시간 별로 데이터를 분할 해 실행 시 작업 시간을 일정 수준 유지할 수 있음

### 타입이 다른 컬럼간 조인

타입이 다른 컬럼 간 조인 시 인덱스의 온전한 사용이 불가

따라서 비교 대상 컬럼의 타입을 맞추어 쿼리 실행 중 발생하는 불필요한 타입 변화 감소

### 테이블 변경은 신중하게

신중하지 못한 테이블 변경은 서비스의 장애로 이어질 수 있음

→ DB는 테이블 변경 시 새 테이블 생성 → 데이터 복사 → 새 테이블 교체 (복사 시간 동안 서비스 정지)

### DB 최대 연결 개수

API 서버 수평 확장 후 DB 연결이 안 되는 경우 → DB 최대 연결 수 확인 필요

** DB 서버 CPU의 사용률이 70% 이상일 경우 DB 부하/성능 저하로 이어질 수 있기 때문에 연결 개수 늘리기 X

# [외부 API 연동] 외부 연동 문제 해결

외부 API 연동 시 연동하는 서비스의 장애는 사용하는 서비스의 장애로 이어짐

## 타임아웃

응답이 나오기까지 대기할 수 있는 시간 설정

```
1. A 서비스의 풀 크기 200
2. 100명의 사용자가 A 서비스에 요청
3. 100개의 요청 처리 가능하기 때문에 처리 시작 / 호출하는 B 서비스에서 응답 X
4. 대기 중인 사용자가 100명 추가 → 동시요청 개수 증가
```

타임아웃을 5초로 걸어주게 되면 B 서비스의 응답을 5초 기다렸다가 에러 응답

→ A 서비스는 들어온 요청들을 처리한 것으로 판단, 따라서 대기 중인 요청을 처리 완료할 수 있음

→ 무한 대기보다는 에러 화면이 더 나음

### 연결 타임아웃

네트워크 연결 시간이 오래 걸리면 대기시간이 증가 → 연결 타임아웃 (3~5초)

### 읽기 타임아웃

연결이 된 후 응답을 받기까지 오래 걸리면 대기시간이 증가 → 읽기 타임아웃 (5~30초)

** 타임아웃 시간이 너무 짧으면 연동 서비스가 처리를 성공해도 타임아웃 에러 발생 가능

## 재시도

외부 연동 시 간헐적으로 연결이 실패하거나 응답이 느려질 수 있음

**조건**

- 단순 조회
- 연결 타임아웃
- 멱등성(연산을 여러 번 적용해도 결과 변화 X)을 가진 변경 기능

** 좋아요와 같이 멱등성이 보장되는 경우에는 재시도 가능

** 포인트 차감 시스템에서 읽기 타임아웃이 났다고 재시도 하게 되면 두 번 차감됨으로 재시도 불가능

**설정**

- 재시도 횟수 → 재시도 횟수만큼 응답 시간 증가하기 때문에 일시적인지, 근본적인지 파악 필요
- 재시도 간격 → 재시도 간격을 점진적으로 늘리는 방식으로 연동 서버 부하 감소

** 재시도 시 연동 서비스는 같은 요청을 두 배로 받게 됨으로 연동 서비스의 성능 상황 고려 필요

## 동시 요청 제한

연동 서비스에 임계치 이상의 요청을 보내게 되면 성능 저하 → 요청을 일정 수준만 보내기

```
1. 연동 서비스가 동시에 처리 가능한 요청이 100개
2. A 서비스에 동시에 300개의 요청이 들어옴
3. 연동 서비스에 100개의 요청만 전달 / 남음 200개의 요청은 503 서버 부하 에러 처리
```

## 서킷 브레이커

연동 서비스가 장애 상황일 때 연동 대신 에러를 응답하고, 정상화되었을 때 연동 재개하는 방식

**상태**

- 닫힘 → 닫힘 상태로 시작, 모든 요청을 연동 서비스에 전달
- 열림 → 실패 건수가 임계치 초과시 열림, 연동 요청 수행 X 에러 응답
    
    → 시간 기준 오류 발생 비율 / 개수 기준 오류 발생 비율
    
- 반 열림 → 열림 상태에서 일정 시간 후 반 열림, 연동 성공 시 닫힘 / 실패 시 열림

https://blog.hwahae.co.kr/all/tech/14541

## 외부 연동과 DB 연동

DB 연동과 외부 연동을 같이 사용할 경우에는 에러 시 DB 트랜잭션을 어떻게 처리할 지 판단 필요

### 외부 연동에 실패했을 때 트랜잭션 롤백

변경된 데이터가 DB에 반영되지 않아 DB 데이터 이상을 방지할 수 있음

하지만, 외부 연동 실패가 읽기 타임아웃일 경우 성공 가능성도 염두해야 함

**트랜잭션 롤백, 하지만 외부 서비스가 실제 성공했을 때 선택할 수 있는 방법**

- 주기적으로 두 시스템 데이터가 일치하는지 확인하고 보정
- 성공 확인 API 호출
- 읽기 타임아웃 발생 시 취소 API 호출

** 성공/취소 API 호출은 외부 서비스가 지원할 때만 가능, 주기적 확인 및 보정 방식이 적합

### 외부 연동 성공했지만 DB 연동 실패했을 때 롤백

취소 API 호출 필요

취소 API가 없거나 취소가 실패할 수도 있기 때문에 주기적으로 데이터 확인 및 보정 작업 지향

### DB 커넥션 풀 문제

만약 DB 쿼리는 0.1초가 걸리지만 외부 연동이 5초 걸리는 상황인 경우

DB 연동과 무관하게 외부 연동을 할 수 있다면 DB 커넥션 전이나 후에 외부 연동 시도 방안 고려 가능

→ 외부 연동이 트랜잭션 밖에서 실행되기 때문에 커밋 이후 롤백이 불가능, 후처리 방안 필요

→ 트랜잭션으로 반영된 데이터를 되돌리는 보상 트랜잭션 등 후처리 방안 …

## HTTP 커넥션 풀

커넥션들을 미리 생성해 보관 → HTTP 연결도 커넥션 풀을 사용하면 연결 시간을 줄일 수 있음

**고려 사항**

- HTTP 커넥션 풀 크기 → 연동 서비스 성능을 고려해 크기 조절 필요 (무분별한 확장은 전체적인 시간 증가)
- 풀에서 HTTP 커넥션을 가져올 떄까지 대기하는 시간 → 대기 시간과 응답 시간은 비례, 짧게 설정 지향
- HTTP 커넥션을 유지할 시간 → 클라이언트 커넥션 풀이 HTTP 커넥션 풀보다 더 오래 유지하면 안 됨
    
    → 죽은 커넥션을 사용할 수도 있음
    

## 연동 서비스 이중화

연동 서비스의 한 곳에 장애가 나도 다른 연동 서비스에서 처리가 가능하도록 이중화

**조건**

- 해당 기능이 서비스의 핵심인가?
- 이중화 비용이 감당 가능한 수준인가?

# [비동기 연동] 스레드, 메시징 등

**동기 연동**

**로그인 프로세스**

```
1. User 정보 조회
2. User가 없으면 에러 반환
3. 암호가 일치하지 않으면 에러 반환
4. 로그인 포인트 지급 서비스 호출
5. 포인트 지급 실패 시 에러 반환
6. 포인트 지급 내역 기록
7. 성공 반환
```

현 작업이 끝날 때까지 다음 작업을 진행하지 않는 동기 방식 이용

→ 포인트 지급 서비스에 장애가 로그인 서비스의 장애를 의미하지는 않음

다음 작업 진행을 위해 반드시 이전 작업의 결과가 필요한 게 아니라면 비동기 방식 연동 고려 

**비동기 연동**

**로그인 프로세스**

```
1. User 정보 조회
2. User가 없으면 에러 반환
3. 암호가 일치하지 않으면 에러 반환
	**별도 스레드**
	1. 로그인 포인트 지급 서비스 호출
	2. 포인트 지급 실패 시 에러 반환
4. 포인트 지급 내역 기록
5. 성공 반환
```

**비동기 연동이 가능한 특징**

- 연동에 시차가 생겨도 문제 X
- 실패 시 재시도 가능
- 실패 시 이후에 수동 처리 가능
- 실패 시 무시해도 되는 기능

## 별도 스레드

별도 스레드를 생성하는 방식으로 비동기 연동 가능 (스레드 풀)

프레임워크에서 제공하는 async 키워드를 사용해 비동기 처리가 가능

** 단, 비동기 처리는 exception을 타지 않기 때문에 내부에서 직접 에러 처리 필요

## 메시징

A 서비스에서 B 서비스로 데이터를 전달할 때 메시징 사용

**장점**

- 서로 영향을 주지 않음 → 메시징 시스템은 각 서비스의 성능에 맞게 메시지 전달, 성능 저하가 영향 X
- 확장 용이 → 메시징 시스템에 연결만 하면 코드 수정 없이 시스템 추가 가능

** 메시징 시스템 - Kafka, 래빗MQ, 레디스 pub/sub ….

메시지 유실되어도 상관 없다 → 레디스 pub/sub

트래픽이 대량으로 발생한다 → Kafka

트래픽이 그렇게 크지 않으면서 메시지를 정확하게 순서대로 전달해야한다 → 래빗MQ

### 메시지 생성 측 고려 사항

생산자와 메시지 시스템 간의 네트워크 연결이 불안정하면 언제든 타임아웃으로 인한 유실 발생 가능

**에러 처리**

- 무시 → 메시지 유실
- 재시도 → 메시지 중복 가능, 메시징 시스템에서 중복 처리에 대해 제공하지 않을 시 별도 처리 필요
- 실패 로그

** 트랜잭션이 끝난 후 메시지를 전송해야 유효한 데이터 전송 가능

### 메시지 소비 측 고려 사항

**중복 케이스 발생 경우**

- 메시지 생산자가 같은 데이터를 가진 메시지 두 번 전송 → 각 메시지에 고유 ID를 부여
- 소비자가 메시지를 처리하는 과정에서 오류로 메시지 재수신 → 명등성을 갖도록 API 구현

**메시지 종류**

- **이벤트** → 어떤 일이 발생했음을 알려주는 메시지
- **커맨드** → 무언가를 요청하는 메시지

## 트랜잭션 아웃박스 패턴

<aside>
💡

</aside>

위 방식을 사용해도 메시징 시스템 연동 실패 가능

메시지 데이터를 DB에 보관하는 방식 → 트랜잭션 내에서 DB 변경 작업 + 아웃박스 테이블에 메시지 추가

아웃박스 패턴을 사용하면 메시지 유실 X, 롤백 시 같이 롤백되어 잘못된 데이터 전송 X

**발송 완료 표기 방법**

- 발송 대기 / 완료 / 실패 상태 저장
- 성공적으로 전송한 마지막 메시지의 ID 별도 기록

## 배치 전송

**프로세스**

```
1. DB에서 전송할 데이터 조회
2. 조회한 결과를 파일로 기록
3. 파일을 연동 시스템에 전송
```

**파일 형식**

- 값1(구분자)값2(구분자) … → 구현 간단, 파싱 속도 빠름
- 이름1=값1 이름2=값2 … → 위치에 관계없이 값 파악 가능, 1번 형식에 비해 용량이 큼
- JSON 문자열 → 대부분 변환 기능을 제공해 쉽게 구현 가능, 데이터 크기가 큼

+ 송수신 주체, 시간, 경로 설정 필요

재처리 기능 → 배치 처리 일정 시간 이후 재전송하는 기능 구현

## CDC

변경된 데이터를 추적하고 판별해 변경된 데이터로 작업을 수행할 수 있도록 하는 설계 패턴

DB는 커밋된 데이터만 CDC에 순서에 맞게 전달 (레코드 단위)

CDC는 변경 데이터 확인/가공 후 대상 시스템에 전파

- 변경 데이터 그대로 전파
- 변경 데이터를 가공/변화해서 전파

두 시스템 간 데이터 동기화 목적 → DB와 DB 사이에 CDC를 두어 복제

메시징 시스템에 데이터를 전파 → 여러 시스템에 변경된 데이터를 둘 수 있어 확장에 유리

** CDC 처리기는 변경 데이터를 어디까지 처리했는지 기록 필요

      → 기록하지 않을 시 마지막 로그 데이터부터 읽어야하는데 이 시간동안의 변경 데이터를 놓침

** CDC는 코드 수정 없이 타 시스템에 관련 데이터를 전파할 수 있음

** CDC는 DB에 변경이 생기면 그걸 자동으로 감지해서 Kafka로 보내줌

# [동시성] 잠금, 원자적 타입 해결

초당 0.1초가 걸리는 100개의 요청이 온다고 가정했을 때 1초 안에 처리하기 위해서는 0.1초에 10개의 요청을 처리해야 함

순서대로 처리한다면 100개의 요청을 처리하는데 10초가 걸림 → TPS가 100에서 10으로 크게 저하

### 클라이언트 요청마다 스레드를 할당해서 처리

요청마다 스레드를 할당 해 여러 스레드가 동시에 코드를 실행하도록 함 → 동시 요청 개수만큼 스레드가 동시에 실행

동시 실행을 고려하지 않고 코드를 작성할 시 찾기 어려운 버그가 생길 수 있음

```jsx
public class Inteaser {
	private int count = 0;
	public void inc() { count = count + 1; }
	public int getCount() { return count; }
}
```

위의 코드를 여러 개의 스레드에서 돌린다고 가정 → 동시에 여러 스레드가 count = count + 1 코드를 실행했을 때 6 → 8이 되어야 하는데 6 → 7이 될 수 있음

** 경쟁 상태 → 여러 스레드가 공유 자원에 접근할 때 접근 순서에 따라 결과가 달라지는 상황 

```jsx
public class PayService {
	private Long payId;
	
	public PayResp pay(PayRequest req) {
		this.payId = getPayId();
		saveTemp(this.payId, req);
		PayResp resp = sendPayData(this.payId, ...);
		applyResponse(resp); → { PayData payData = createPayData(resp); updatePayData(this.payId, payData); }
		return resp;
	}
}
```

다음과 같은 코드에서 만약 PayService가 싱글톤 객체 상황이라면 다중 스레드 환경에서 동시 사용시 값이 달라질 수 있음

```jsx
스레드 1 - payId를 1로 생성                                                    → updatePayData(payId, payData)
스레드 2 -                  → payId를 2로 생성 → updatePayData(payId, payData)
							payId : 1         payId : 2               payId : 2                        payId : 2
```

스레드 1에서 사용하던 payId에 대한 데이터가 스레드 2의 데이터로 덮어씌워지게 되면서 스레드 1은 올바르지 않은 데이터를 수정하게 됨

마찬가지로, DB도 동시에 데이터를 변경하게 되면 동시성 문제가 발생할 수 있음

** 싱글톤 패턴 → 싱글톤 패턴은 객체 지향 프로그래밍에서 특정 클래스가 단 하나만의 인스턴스를 생성하여 사용하기 위한 패턴

인스턴스를 여러개 만들면서 생기는 불필요한 자원 낭비나 예상치 못한 결과를 방지하기 위해 단 한 번 생성 후 전역에서 객체를 공유 사용

단, 내부에 상태값(멤버 변수)을 가지고 있으면 스레드 간 공유되므로 상태를 변경하지 않거나 불변객체로 유지해야 함

## 프로세스 수준에서 동시 접근 제어

단일 프로세스 내에서 동시성을 다룰 때 필요한 기초 개념

### 잠금(lock)을 이용한 접근 제어

공유 자원에 접근하는 스레드를 한 번에 하나로 제한

1. 잠금 획득
2. 공유 자원에 접근 (임계 영역 → 동시에 둘 이상의 스레드나 프로세스가 접근하면 안되는 공유 자원에 접근하는 코드 영역)
3. 잠금 해제

→ 여러 스레드에서 동시에 잠금 획득을 시도할 시 하나만 획득하고 나머지는 대기 상태

** Java synchronized vs ReentrantLock

synchronized → 간단하게 동시 접근 제어 가능 (코드 블록 종료 시 자동 잠금 해제)

ReentrantLock → 잠금 획득 대기 시간 등 synchronized에서 지원하지 않는 기능 제공

UserSessions가 동시성 문제가 없는지 확인하기 위한 테스트

→ lock을 사용해 500개의 데이터를 넣게 되면 객체가 정상적으로 추가된 것을 확인할 수 있음

→ lock을 사용하지 않고 500개의 데이터를 넣게 되면 객체가 없다는 에러가 나는 것을 확인할 수 있음

** Mutex → mutual exclusion의 줄임말, 프로그래밍 언어에 따라 Lock 또는 Mutex 언어를 사용

ReentrantLock의 경우 한 번에 하나의 스레드만 잠금을 획득할 수 있음 → 나머지 스레드는 잠금 해제될 때까지 대기

따라서 잠금 이외에도 동시 접근 제어를 위한 구성요소 존재

잠금은 안전하지만 성능에 영향을 줄 수 있으므로 임계 구역을 최소화해야 함

### 세마포어

동시에 실행할 수 있는 스레드 수 제한 → 자원에 대한 접근을 일정 수준으로 제한하고 싶다면 세마포어 사용 가능 (자바에서는 구현체를 permit / Go에서는 weight으로 표현)

1. 세마포어에서 퍼밋 획득 (퍼밋 개수 - 1)
2. 코드 실행
3. 세마포어에 퍼밋 반환 (퍼밋 개수 + 1)

→ 더이상 세마포어에 사용할 수 있는 퍼밋이 없다면 스레드들은 다른 스레드가 퍼밋을 반환할 때까지 대기

세마포어는 "동시 접근 허용 개수"를 제어하고 싶을 때 사용, lock은 "1개만 접근 허용"일 때 사용

### 읽기 쓰기 잠금

UserSessions가 동시성 문제가 없는지 확인하기 위한 테스트에서 HashMap의 데이터를 get(), put() 할 때 둘 다 lock을 걸게 된다면

get()을 실행하는 동안 put()을 사용해 HashMap이 변경되지만 않는다면 문제 X, get + put 동시 실행 X, get만 동시 실행 O

get, put 모두 잠금을 걸어두면 get 실행시에도 한 스레드만 읽기가 가능 해 읽기 성능이 떨어짐

- 쓰기 잠금은 한 번에 한 스레드만 구할 수 있음
- 읽기 잠금은 한번에 여러 스레드를 구할 수 있음
- 한 스레드가 쓰기 잠금을 획득했다면 쓰기 잠금이 해제될 때까지 읽기 잠금을 구할 수 없음
- 읽기 스레드가 획득한 모든 스레드가 읽기 잠금을 해제할 때까지 쓰기 잠금을 구할 수 없음

→ ReentrantReadWriteLock을 사용하면 읽기/쓰기 잠금을 구분해서 처리 가능

### 원자적 타입 (Atomic Type)

```java
public class Inteaser {
	private int count = 0;
	public void inc() { count = count + 1; }
	public int getCount() { return count; }
}
```

이 코드에서 inc() 시 락을 걸게되면 동시성 문제를 해결할 수 있지만 CPU 효율이 떨어짐

→ 자바에서 AtomicInteger / AtomicLong / AtomicBoolean과 같은 원자적 타입을 사용해 다중 스레드 환경에서 동시성 문제 없이 데이터 변경이 가능

내부에서 Compare And Swap 연산 실행 

** **Compare And Swap**

1. 멀티스레드, 멀티코어 환경의 경우 각 변수를 스레드 내의 스택(캐시)에 저장
2. 변수에 대해서 변경 시 스레드 저장 값과 메인 메모리 저장값 비교
3. 값이 같다면 치환 / 다르다면 계속 재시도

→ 락보다 빠르지만 재시도가 많아질 경우 오히려 비용이 커질 수 있음

### 동시성 지원 컬렉션

HashMap, HashSet은 동시성 문제 발생

→ Collections 클래스의 경우 동기화된 컬렉션을 생성하는 synchronizedMap 메서드 제공

→ 동시성 자체를 지원하는 ConcurrentHashMap 등 사용

동시성 문제를 해결하기 위해 불변값 사용 가능

** 불변값 → 바뀌지 않는 값, 데이터 변경이 필요한 경우 기존 값 수정 X, 새로운 값을 생성해 사용

## [동시성] DB와 동시성

DB 트랜잭션은 여러 개의 조회나 쓰기를 논리적으로 하나의 연산으로 묶어줌 (커밋, 롤백) → 트랜잭션만으로는 동시성 문제 해결 X

- 선점 잠금 → 동일한 레코드에 대해 한 번에 하나의 트랜잭션만 접근할 수 있도록 제어
- 비선점 잠금 / 낙관적 잠금 → 값을 비교해서 수정하는 방식, 쿼리 실행 자체는 막지 않으면서 데이터의 잘못된 변경 방지

### 선점 잠금 (비관적 잠금)

데이터에 먼저 접근한 트랜잭션이 잠금을 획득하는 방식

```
트랜잭션 1 - select * from A where id = 1 for update → update A ... → 커밋
트랜잭션 2 -          select * from A where id = 1 for update              → update A ... → 커밋
                트랜잭션 1 lock 획득                                       → 트랜잭션 2 lock 획득
```

→ 동시에 같은 데이터를 수정하면서 데이터 일관성이 깨지는 것을 방지

** 분산 잠금→ 여러 프로세스가 동시에 동일한 자원에 접근하지 못하도록 막는 방법, 여러 프로세스 간 잠금 처리를 함 (레디스로도 빠르게 적용 가능) 

### 비선점 잠금 (낙관적 잠금)

명시적으로 잠금을 사용하지 않고, 데이터를 조회한 시점의 값과 수정하려는 시점의 값이 같은지 비교하는 방식

→ 보통 version 컬럼을 사용해 비선점 잠금 구현

```
1. select 쿼리 실행 시 version 컬럼 함께조회
2. 로직 수행
3. update 쿼리 실행 시 version 컬럼 + 1, version 컬럼 값이 1에서 조회한 값과 같은지 비교하는 조건을 where 절에 추가
4. update 결과로 변경된 행 개수가 0이면 다른 트랜잭션에서 값을 변경한 것임으로 트랜잭션 롤백
5. update 결과로 변경된 행 개수가 0보다 크면 다른 트랜잭션보다 먼저 값을 변경한 것임으로 트랜잭션 커밋 
```

→ 일단 데이터 변경을 시도해 선점 잠금과 비교했을 때 대기 과정이 없어 실패 시 빠르게 결과를 응답할 수 있음

### 외부 연동과 잠금

트랜잭션 범위 내에서 외부 시스템과 연동해야 한다면 비선점 잠금보다는 선점 잠금 추천

→ 주문 취소 과정에서 외부 PG 시스템 호출해서 결제까지 함께 취소한다고 가정

- 비선점 잠금 - 결제는 이미 취소되었는데 상태가 주문 시작이라서 롤백할 수도 있음 → 트랜잭션 아웃박스 패턴을 통해 처리할 수도 있음

### 증분 쿼리

```
1. 주제 조회
2. 참여 데이터 추가
3. subject.getCount() + 1을 통해 주제 데이터 참여자 수 증가
```

→ 여러 개의 사용자가 동시에 실행하게 되면 1만 증가하는 문제 발생 가능

→ 선점 방식을 사용할 수도 있지만, joinCount = joinCount + 1을 통해 순차적으로 실행하게 할 수도 있음

** 항상 원자적 연산이 아닐 수도 있기 때문에 검증 과정 필요

## 주의사항

### 잠금 해제

잠금을 획득한 후에는 반드시 해제하는 과정이 필요 → 잠금을 시도하는 스레드가 무한정 대기할 수도 있음

세마포어도 퍼밋 획득 후 반드시 반환하는 과정이 필요

### 대기 시간 지정

동시 접근이 많아지게 되면 잠금 획득을 위해 대기하는 시간이 길어질 수 있음 → 대기 시간 지정

`tryLock(시간, 시간타입)`을 통해 일정 시간 동안 잠금을 획득하지 못한다면 실패 처리

`tryLock()`을 통해 대기 시간 없이 바로 결과를 반환할 수도 있음

→ 사용자에게 빠르게 응답함으로 불안감 감소

### 교착 상태 피하기

교착 상태 → 2개 이상의 스레드가 서로가 획득한 잠금을 대기하면서 무한히 기다리는 상황

```
스레드 1 - 자원 A 잠금 획득 → 자원 B 잠금 대기
스레드 2 - 자원 B 잠금 획득 → 자원 A 잠금 대기
```

→ 서로가 서로의 잠금이 필요해 무한정으로 대기하게 됨

**해결 방법**

1. 잠금 대기 시간 제한 → 무한정 대기하지 않고 일정 시간이 지나면 실패하면서 교착 상태를 풀 수 있음
2. 지정한 순서대로 잠금 획득 → 두 스레드 모두 자원 A에 대해 잠금을 시도하고 B에 대해 잠금을 시도하도록 설정해 교착 상태가 일어나지 않도록 할 수 있음

** 라이브락 → 활동을 하는 것 같지만 실제로는 아무것도 하지 않는 상태 (우선순위를 두거나 임의성을 주는 방식으로 해결 가능)

** 기아 상태 → 우선 순위가 높은 작업이 많아 낮은 작업이 실행이 안 되는 상황 (실행 안되는 작업의 우선순위를 높이거나 공유 자원 독점 시간에 제한을 두는 방식으로 해결 가능)

## 단일 스레드로 처리

동시성 문제의 주된 원인 → 여러 스레드가 동시에 동일한 자원에 접근하기 때문에

→ 애초에 한 스레드로만 처리 해 동시성 해결

```
작업 요청 스레드 1 --|
작업 요청 스레드 2 --|-- 작업 큐 -- 상태 관리 스레드
작업 요청 스레드 3 --|
```

→ 데이터 변경이나 접근이 필요한 스레드는 작업 큐에 작업을 넣기만 하고 직접 상태에 접근 불가

→ 상태 관리 스레드는 작업 큐에서 작업을 꺼내어 필요한 작업을 순차적으로 수행 → 잠금과 같은 수단이 필요 없어 코드가 단순해짐

두 스레드가 데이터 공유가 필요하다면 콜백이나 큐와 같은 수단을 사용해 복제본 공유 또는 불변 값 공유 → 다른 스레드에서 원본 데이터를 수정하지 못하도록 해 동시성 문제 방지

** Go에서는 여러 고루틴이 동시에 접근하는 것을 막기 위해 잠금 수단을 제공하지만 채널을 통해 고루틴을 공유하는 방식 권장

단일 스레드로 처리하면 동시성 문제는 해결 → 구조가 복잡해지는 단점 (논블로킹이나 비동기IO 사용하는 경우 블로킹 연산을 최소화해야 해 단일 스레드 방식이 적합)

** 성능→ 임계 영역 실행시간이 짧고 동시 접근 스레드 수가 적으면 Lock 유리, 동시 실행이 많고 임계 영역 실행이 길면 Queue나 Channel 방식 유리
