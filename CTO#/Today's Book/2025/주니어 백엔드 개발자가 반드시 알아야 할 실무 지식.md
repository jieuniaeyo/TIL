# \[처리량과 응답시간\] 커넥션풀, 캐싱

## 응답 시간

`[서버 연결 → 서버로 요청 전송 → /서버 실행/ → 클라이언트로 요청 전송]`
다음 과정을 거치는데 소요된 시간

-   Time To First Byte 응답의 첫 번째 바이트 도착까지 걸린 시간 (ms)
-   Time To Last Byte 응답의 마지막 바이트 도착까지 걸린 시간 (ms)

응답 시간과 사용자의 만족도의 상관관계

응답 시간을 줄인다고 만족도 반드시 증가 X, 하지만 응답 시간이 늘어나면
만족도는 확실히 감소

### 응답 시간에 영향을 주는 요인

-   로직 수행
-   DB 연동
-   외부 API 연동
-   응답 데이터 생성

→ 실제로 API 연동과 DB 연동이 대부분의 응답 시간을 차지

## 처리량 (Transaction Per Second)

단위당 시간 시스템이 처리하는 작업량

\*\* 이때 처리에 초점 즉, 0초에 시작되어 3초에 끝나는 작업이 있다면
3초의 처리량으로 카운트

서버가 처리할 수 있는 TPS를 초과한다면 서버는 초과된 요청을 나중에 처리

→ 이로 인해 초과된 요청을 보낸 사용자는 앞선 요청이 처리될 때까지
대기해야함 = 응답 시간 증가

**해결방법**

-   서버가 처리할 수 있는 요청 수 자체를 늘리기
-   처리 시간 자체를 줄이기

TPS를 늘리기 위해 먼저 해야 할 작업은 병목 지점 찾기

### 수직 확장

서버의 자원(CPU, 메모리, 디스크 등)을 증가시키는 방식

→ 즉각적인 효과를 얻을 수 있지만, 트래픽이 증가하면 결국 성능 문제가
다시 발생

서버가 다운되지 않도록 임시로 유지하면서, 그 시간 동안 근본적인 해결
방안을 찾는 용도로 활용

### 수평 확장

서버의 개수를 늘리는 방식

→ DB에 병목이 있다면 수평 확장 시 오히려 DB 부하가 증가할 수 있음

따라서, 병목 지점을 정확히 파악하는 것이 중요

외부 API나 DB 성능이 문제라면 수평 확장 시 각 요소에 더 많은 트래픽이
집중되어 TPS 향상 효과가 없음

## DB 커넥션 풀

DB 사용 시

1.  DB 연결
2.  쿼리 실행
3.  사용이 끝날 시 DB 연결 종료

보통 DB 연결 시 및 종료에 0.5초 \~ 1초의 시간 소요

만약 10ms의 쿼리를 실행하고 DB 연결 및 종료에 50ms가 소요된다면 전체
시간의 80%가 소요

### 커넥션 풀

커넥션들을 미리 생성해 보관 → DB 사용 시 커넥션을 가져와 사용하고 다시
풀에 반환 (재사용)

**주요 설정**

-   커넥션 풀 크기
-   커넥션 대기 시간
-   커넥션 유지 시간

### 커넥션 풀 크기

커넥션 풀에 미리 생성해둘 커넥션 개수 설정

-   최소 커넥션 수 (Minimum Pool Size): 풀에 항상 유지할 최소 커넥션
    개수
-   최대 커넥션 수 (Maximum Pool Size): 풀에서 생성할 수 있는 최대
    커넥션 개수

```{=html}
<!-- -->
```
    if) 커넥션 풀 크기 → 5
            쿼리 실행 → 0.1
    →   1초에 50개의 요청 처리 가능

    if) 커넥션 풀 크기 → 5
            쿼리 실행 → 0.5
    →   1초에 10개의 요청 처리 가능 

따라서 쿼리 실행에 걸리는 시간에 따라 적절한 크기를 설정해야 함

최소/최대 커넥션 수 설정을 통해 트래픽에 따라 커넥션 개수를 필요한 만큼
유지 가능

\*\* DB 부하가 큰 상황에서 커넥션 개수를 늘리면 오히려 쿼리 실행 시간이
증가될 수 있음

### 커넥션 대기 시간

풀에 사용할 수 있는 커넥션이 없을 때 대기할 수 있는 최대 시간 (보통
0.5초 \~ 3초 이내 설정)

-   커넥션 대기 시간 (Connection Timeout): 사용 가능한 커넥션이 없을 때
    대기하는 최대 시간

```{=html}
<!-- -->
```
    if) 커넥션 풀 크기 → 10
            쿼리 실행 → 10초
            요청 → 20개
            대기 시간 → 30초
    →   10개의 요청이 대기 상태 → 에러 응답이 없어 대기 중인 사용자가 재시도 → 동시 요청 수 30개

    if) 커넥션 풀 크기 → 10
            쿼리 실행 → 10초
            요청 → 20개
            대기 시간 → 5초
    →   10개의 요청이 대기 상태 → 5초 후 에러 응답을 받음 → 동시 요청 수 10개

대기 시간 동안 사용자가 재요청을 할 시 기존 요청 취소 X 신규로 요청이
들어옴

→ 즉, 에러 응답이 나오지 않아 사용자가 새로고침을 한다면 동시 요청 수가
계속해서 증가

### 커넥션 유지 시간

커넥션이 사용되지 않는 시간이 길어지면 연결 종료

-   유휴 커넥션 타임아웃 (Idle Timeout): 사용되지 않는 커넥션을 풀에서
    제거하기까지의 시간

→ DB 설정 비활성화 유지 시간보다 짧을 시 DB가 연결을 끊기 전 커넥션에서
먼저 제거 가능

-   유효성 검사 (Validation Query): 커넥션이 정상적으로 사용 가능한
    상태인지 확인

→ 커넥션을 가져올 때 유효성을 검사하거나 주기적으로 검사 가능

-   커넥션 최대 수명 (Max Lifetime): 커넥션이 생성된 후 풀에서 유지되는
    최대 시간

→ 커넥션이 유효하더라도 최대 수명이 지나면 풀에서 제거

\*\* 최대 유휴 시간 / 유지 시간 무한대로 설정 지양

## 캐시

동일한 데이터를 요청할 때 DB가 아닌 캐시에서 데이터를 읽어와 응답 (자주
조회되는 데이터 저장 적합)

### 적중률

캐시가 얼마나 효율적으로 사용되는 지 판단

    캐시에 존재하는 데이터의 개수 / 캐시에서 조회를 시도한 횟수

적중률이 높을 수록 DB 연동 감소, 응답 시간 감소, DB 부하 감소로 이어짐

하지만 캐시 메모리 용량에는 한계가 있기 때문에 기존 데이터들을 제거해야
함

**캐시 삭제 규칙**

-   Least Recently Used: 가장 오래전 사용된 데이터 제거
-   Least Frequently Used: 가장 적게 사용된 데이터 유지
-   First In First Out: 가장 먼저 들어온 데이터 제거

### 로컬 캐시 vs 리모트 캐시

**로컬 캐시**

장점 - 속도가 빠름 (서버 프로세스와 동일한 메모리를 사용하기 때문에)

단점 - 데이터 크기에 제한, 서버 프로세스 재시작 시 캐시 삭제

**리모트 캐시**

장점 - 캐시 크기 확장 가능, 서버 프로세스가 재시작 되더라도 캐시 유지

단점 - 속도가 느림 (네트워크 통신이 필요하기 때문에 로컬에 비해
상대적으로 느림)

\*\* 데이터 규모가 작고 변경 빈도가 잦다면 로컬 캐시 적합

\*\* 데이터 규모가 크고 배포 빈도가 잦다면 리모트 캐시 적합

**사전 적재**

트래픽이 특정 순간에 급증하는 패턴을 보인다면 미리 캐시에 저장하는 방향
고려 필요

    if) 사용자가 500만 명인 앱에서 특정 쿠폰 발급 → 당일 10%의 사용자가 접속해도 트래픽 100만
    → 미리 500만개의 데이터를 캐시에 저장해두면 당일 10%의 사용자가 접속해도 적중률 99% 이상 유지 가능

**캐시 무효화**

유효하지 않는 데이터를 적절한 시점에 캐시에서 삭제하는 것

-   민감한 데이터 → 원본 데이터 변경시 즉시 캐시 무효화, 리모트 캐시
    저장 (다른 서버 로컬 캐시 변경 X)
-   일반 데이터 → 유효시간을 설정해 주기적으로 갱신

**가비지 컬렉터 / 메모리 사용**

사용하지 않는 메모리를 찾아 반환 → 자바의 경우 가비지 컬렉터가 실행되는
동안 모든 실행 일시 중단

\*\* 메모리 사용량과 GC 시간은 비례 (실제 메모리 사용 패턴에 맞게 최대
힙 크기 조절)

대량 객체 생성 시 메모리 부족 상태 지속 → 데이터 개수 / 조회 범위를
트래픽 규모와 메모리 크기에 맞춰 제한

\*\* 파일 다운로드와 같은 기능 구현 시 스트림을 사용하면 한 번에 읽는
것에 비해 메모리 절약 가능

# [처리량과 응답시간] 응답 데이터 압축

응답시간에는 데이터 전송 시간도 포함

**영향 요인**

- 네트워크 속도
- **데이터 크기 → 응답하는 데이터를 압축해 전송하면 전송 시간을 줄일 수 있음**

**고려 사항**

- 데이터 압축 시 텍스트 형식의 데이터는 압축률이 높아 효과적, 이미 압축된 데이터들은 압축률이 낮아 효과 X
- 응답 데이터가 압축되지 않았다면 방화벽이 해제했을 수 있어 확인 필요

## 정적 자원

정적 자원 로드는 전체 트래픽의 상당 부분을 차지 → 실제 동작과 무관하게 불필요한 트래픽 차지

### 클라이언트 캐시 사용

Cache-Control 헤더를 사용해 응답 데이터를 전송하게 되면 설정된 시간만큼 서버 요청 X 캐시 데이터 사용

단, 클라이언트 캐시는 브라우저 단위로 작동 → 즉, 특정 시간대에 다수의 신규 사용자가 접속시 트래픽 증가

### CDN 사용 (Content Delivery Network)

콘텐츠 전송을 위한 별도의 네트워크 사용

**동작 방식**

1. CDN url을 통해 콘텐츠 접근
2. 만약 CDN이 해당 콘텐츠를 가지고 있지 않다면 오리진 서버에서 읽어와 제공
3. 해당 콘텐츠는 CDN에 캐시
4. 이후 같은 콘텐츠에 대한 요청이 들어오면 CDN에서 처리

→ 동일한 콘텐츠에 대해 여러번 요청이 들어와도 서버에서는 최초 한 번만 담당

** CDN은 여러 지역에 서버를 두어 가까운 곳에서 더 빠르게 콘텐츠 응답이 가능

## 대기 처리

티켓팅과 같이 짧은 시간 동안 폭증하는 트래픽

**해결 방법**

- 서버 / DB 증설
    
    → 증설된 서버는 줄일 수 있지만, DB는 X 즉, 특정 트래픽을 막기 위해 DB 고정 비용 증가
    
- 수용할 수 있는 인원 수 자체를 축소
    
    → 대량의 트래픽 전체를 처리하자 X 수용이 가능한 트래픽만 받고 나머지는 대기처리하자 O
    
    → 서버 증설하지 않고 안정적 트래픽 제공 가능, 사용자의 새로고침으로 인한 트래픽 폭증 방지


# [DB 설계 쿼리] 조회 성능 개선, 주의 사항

## 성능 개선 방법

### 미리 집계

게시글 좋아요 카운트

`select count() from like where id = @` count나 sum 같은 집계 함수는 실행 시간이 오래 걸림

게시글 테이블에 like_count 컬럼을 추가하고, 좋아요 발생 시 ±1 연산으로 미리 집계

### ID 기준 목록 조회 사용

10만 번째 게시글부터 10개 조회

`limit 10 offset 99990` → 99991번째부터 조회하는 것이 아니라, 99990개를 센 후 나머지 10개를 조회하므로 실행 시간이 오래 걸림

`where id > 99990 limit 10` → 99991번째부터 바로 조회 가능

### 조회 범위 제한

특정 사용자 게시글 조회

특정 사용자가 작성한 게시글 전체 조회 → 실행 시간이 오래 걸림

최근 3개월 또는 6개월로 범위를 제한해서 조회 → 최신 데이터 위주로 조회하면 DB 성능 향상, 캐싱 적중률 증가

### 전체 개수 카운트 지양

인덱스를 사용해도 전체 스캔이 발생하고, 인덱스를 사용하지 않으면 실제 데이터를 전부 스캔

따라서 전체 개수를 표시하는 방식은 지양

### 오래된 데이터 삭제 및 분리

데이터 개수와 쿼리 실행 시간은 비례

일정 수준 이상 쌓인 데이터는 삭제하거나 별도로 분리

### DB 장비 확장

DB 부하로 인한 성능 문제 발생 시 → 수직 확장으로 서비스 안정화 및 개선 시간 확보

클라우드 사용 시 DB 성능 향상이 용이

DB 수평 확장 시 처리 가능한 트래픽 증가 (주 DB + 복제 DB 구조)

### 별도 캐시 서버 구축

동일한 데이터 요청으로 인한 DB 부하를 줄이기 위해 별도의 캐시 서버 구축

DB 확장보다 Redis와 같은 캐시 서버 구성이 비용 부담이 적음

## 주의 사항

### 쿼리 타임아웃

트래픽이 증가 해 쿼리 실행 시간이 1초에서 5초가 되었다고 가정

쿼리 타임아웃을 두지 않으면 대기중인 사용자의 재시도로 인해 서버 부하 폭증 가능

타임아웃을 3초로 설정 시 사용자는 에러를 보지만 서버 입장에서는 요청이 정상 종료 → 서버 부하를 줄일 수 있음

### 상태 변경 기능 조회는 복제 DB에서 하지 않기

주 DB에서 복제 DB는 순간적으로 데이터가 일치하지 않을 수 있음

→ 주 DB에서 상태 변경 후 복제 DB 반영까지 시간이 걸릴 수 있음 (트랜잭션 커밋 시점에 이루어짐)

따라서, 상태 변경에 대한 데이터 조회는 주 DB에서 실행

### 배치 쿼리 실행 시간 증가

데이터의 증가로 집계 배치 쿼리의 실행시간이 증가했을 떄 해결책

- 커버링 인덱스 사용 → 집계 시 사용되는 데이터 인덱스를 설계 해 전체 데이터를 스캔하지 않도록 조절
- 데이터 분할 → 특정 시간 별로 데이터를 분할 해 실행 시 작업 시간을 일정 수준 유지할 수 있음

### 타입이 다른 컬럼간 조인

타입이 다른 컬럼 간 조인 시 인덱스의 온전한 사용이 불가

따라서 비교 대상 컬럼의 타입을 맞추어 쿼리 실행 중 발생하는 불필요한 타입 변화 감소

### 테이블 변경은 신중하게

신중하지 못한 테이블 변경은 서비스의 장애로 이어질 수 있음

→ DB는 테이블 변경 시 새 테이블 생성 → 데이터 복사 → 새 테이블 교체 (복사 시간 동안 서비스 정지)

### DB 최대 연결 개수

API 서버 수평 확장 후 DB 연결이 안 되는 경우 → DB 최대 연결 수 확인 필요

** DB 서버 CPU의 사용률이 70% 이상일 경우 DB 부하/성능 저하로 이어질 수 있기 때문에 연결 개수 늘리기 X

# [외부 API 연동] 외부 연동 문제 해결

외부 API 연동 시 연동하는 서비스의 장애는 사용하는 서비스의 장애로 이어짐

## 타임아웃

응답이 나오기까지 대기할 수 있는 시간 설정

```
1. A 서비스의 풀 크기 200
2. 100명의 사용자가 A 서비스에 요청
3. 100개의 요청 처리 가능하기 때문에 처리 시작 / 호출하는 B 서비스에서 응답 X
4. 대기 중인 사용자가 100명 추가 → 동시요청 개수 증가
```

타임아웃을 5초로 걸어주게 되면 B 서비스의 응답을 5초 기다렸다가 에러 응답

→ A 서비스는 들어온 요청들을 처리한 것으로 판단, 따라서 대기 중인 요청을 처리 완료할 수 있음

→ 무한 대기보다는 에러 화면이 더 나음

### 연결 타임아웃

네트워크 연결 시간이 오래 걸리면 대기시간이 증가 → 연결 타임아웃 (3~5초)

### 읽기 타임아웃

연결이 된 후 응답을 받기까지 오래 걸리면 대기시간이 증가 → 읽기 타임아웃 (5~30초)

** 타임아웃 시간이 너무 짧으면 연동 서비스가 처리를 성공해도 타임아웃 에러 발생 가능

## 재시도

외부 연동 시 간헐적으로 연결이 실패하거나 응답이 느려질 수 있음

**조건**

- 단순 조회
- 연결 타임아웃
- 멱등성(연산을 여러 번 적용해도 결과 변화 X)을 가진 변경 기능

** 좋아요와 같이 멱등성이 보장되는 경우에는 재시도 가능

** 포인트 차감 시스템에서 읽기 타임아웃이 났다고 재시도 하게 되면 두 번 차감됨으로 재시도 불가능

**설정**

- 재시도 횟수 → 재시도 횟수만큼 응답 시간 증가하기 때문에 일시적인지, 근본적인지 파악 필요
- 재시도 간격 → 재시도 간격을 점진적으로 늘리는 방식으로 연동 서버 부하 감소

** 재시도 시 연동 서비스는 같은 요청을 두 배로 받게 됨으로 연동 서비스의 성능 상황 고려 필요

## 동시 요청 제한

연동 서비스에 임계치 이상의 요청을 보내게 되면 성능 저하 → 요청을 일정 수준만 보내기

```
1. 연동 서비스가 동시에 처리 가능한 요청이 100개
2. A 서비스에 동시에 300개의 요청이 들어옴
3. 연동 서비스에 100개의 요청만 전달 / 남음 200개의 요청은 503 서버 부하 에러 처리
```

## 서킷 브레이커

연동 서비스가 장애 상황일 때 연동 대신 에러를 응답하고, 정상화되었을 때 연동 재개하는 방식

**상태**

- 닫힘 → 닫힘 상태로 시작, 모든 요청을 연동 서비스에 전달
- 열림 → 실패 건수가 임계치 초과시 열림, 연동 요청 수행 X 에러 응답
    
    → 시간 기준 오류 발생 비율 / 개수 기준 오류 발생 비율
    
- 반 열림 → 열림 상태에서 일정 시간 후 반 열림, 연동 성공 시 닫힘 / 실패 시 열림

https://blog.hwahae.co.kr/all/tech/14541

## 외부 연동과 DB 연동

DB 연동과 외부 연동을 같이 사용할 경우에는 에러 시 DB 트랜잭션을 어떻게 처리할 지 판단 필요

### 외부 연동에 실패했을 때 트랜잭션 롤백

변경된 데이터가 DB에 반영되지 않아 DB 데이터 이상을 방지할 수 있음

하지만, 외부 연동 실패가 읽기 타임아웃일 경우 성공 가능성도 염두해야 함

**트랜잭션 롤백, 하지만 외부 서비스가 실제 성공했을 때 선택할 수 있는 방법**

- 주기적으로 두 시스템 데이터가 일치하는지 확인하고 보정
- 성공 확인 API 호출
- 읽기 타임아웃 발생 시 취소 API 호출

** 성공/취소 API 호출은 외부 서비스가 지원할 때만 가능, 주기적 확인 및 보정 방식이 적합

### 외부 연동 성공했지만 DB 연동 실패했을 때 롤백

취소 API 호출 필요

취소 API가 없거나 취소가 실패할 수도 있기 때문에 주기적으로 데이터 확인 및 보정 작업 지향

### DB 커넥션 풀 문제

만약 DB 쿼리는 0.1초가 걸리지만 외부 연동이 5초 걸리는 상황인 경우

DB 연동과 무관하게 외부 연동을 할 수 있다면 DB 커넥션 전이나 후에 외부 연동 시도 방안 고려 가능

→ 외부 연동이 트랜잭션 밖에서 실행되기 때문에 커밋 이후 롤백이 불가능, 후처리 방안 필요

→ 트랜잭션으로 반영된 데이터를 되돌리는 보상 트랜잭션 등 후처리 방안 …

## HTTP 커넥션 풀

커넥션들을 미리 생성해 보관 → HTTP 연결도 커넥션 풀을 사용하면 연결 시간을 줄일 수 있음

**고려 사항**

- HTTP 커넥션 풀 크기 → 연동 서비스 성능을 고려해 크기 조절 필요 (무분별한 확장은 전체적인 시간 증가)
- 풀에서 HTTP 커넥션을 가져올 떄까지 대기하는 시간 → 대기 시간과 응답 시간은 비례, 짧게 설정 지향
- HTTP 커넥션을 유지할 시간 → 클라이언트 커넥션 풀이 HTTP 커넥션 풀보다 더 오래 유지하면 안 됨
    
    → 죽은 커넥션을 사용할 수도 있음
    

## 연동 서비스 이중화

연동 서비스의 한 곳에 장애가 나도 다른 연동 서비스에서 처리가 가능하도록 이중화

**조건**

- 해당 기능이 서비스의 핵심인가?
- 이중화 비용이 감당 가능한 수준인가?

# [비동기 연동] 스레드, 메시징 등

**동기 연동**

**로그인 프로세스**

```
1. User 정보 조회
2. User가 없으면 에러 반환
3. 암호가 일치하지 않으면 에러 반환
4. 로그인 포인트 지급 서비스 호출
5. 포인트 지급 실패 시 에러 반환
6. 포인트 지급 내역 기록
7. 성공 반환
```

현 작업이 끝날 때까지 다음 작업을 진행하지 않는 동기 방식 이용

→ 포인트 지급 서비스에 장애가 로그인 서비스의 장애를 의미하지는 않음

다음 작업 진행을 위해 반드시 이전 작업의 결과가 필요한 게 아니라면 비동기 방식 연동 고려 

**비동기 연동**

**로그인 프로세스**

```
1. User 정보 조회
2. User가 없으면 에러 반환
3. 암호가 일치하지 않으면 에러 반환
	**별도 스레드**
	1. 로그인 포인트 지급 서비스 호출
	2. 포인트 지급 실패 시 에러 반환
4. 포인트 지급 내역 기록
5. 성공 반환
```

**비동기 연동이 가능한 특징**

- 연동에 시차가 생겨도 문제 X
- 실패 시 재시도 가능
- 실패 시 이후에 수동 처리 가능
- 실패 시 무시해도 되는 기능

## 별도 스레드

별도 스레드를 생성하는 방식으로 비동기 연동 가능 (스레드 풀)

프레임워크에서 제공하는 async 키워드를 사용해 비동기 처리가 가능

** 단, 비동기 처리는 exception을 타지 않기 때문에 내부에서 직접 에러 처리 필요

## 메시징

A 서비스에서 B 서비스로 데이터를 전달할 때 메시징 사용

**장점**

- 서로 영향을 주지 않음 → 메시징 시스템은 각 서비스의 성능에 맞게 메시지 전달, 성능 저하가 영향 X
- 확장 용이 → 메시징 시스템에 연결만 하면 코드 수정 없이 시스템 추가 가능

** 메시징 시스템 - Kafka, 래빗MQ, 레디스 pub/sub ….

메시지 유실되어도 상관 없다 → 레디스 pub/sub

트래픽이 대량으로 발생한다 → Kafka

트래픽이 그렇게 크지 않으면서 메시지를 정확하게 순서대로 전달해야한다 → 래빗MQ

### 메시지 생성 측 고려 사항

생산자와 메시지 시스템 간의 네트워크 연결이 불안정하면 언제든 타임아웃으로 인한 유실 발생 가능

**에러 처리**

- 무시 → 메시지 유실
- 재시도 → 메시지 중복 가능, 메시징 시스템에서 중복 처리에 대해 제공하지 않을 시 별도 처리 필요
- 실패 로그

** 트랜잭션이 끝난 후 메시지를 전송해야 유효한 데이터 전송 가능

### 메시지 소비 측 고려 사항

**중복 케이스 발생 경우**

- 메시지 생산자가 같은 데이터를 가진 메시지 두 번 전송 → 각 메시지에 고유 ID를 부여
- 소비자가 메시지를 처리하는 과정에서 오류로 메시지 재수신 → 명등성을 갖도록 API 구현

**메시지 종류**

- **이벤트** → 어떤 일이 발생했음을 알려주는 메시지
- **커맨드** → 무언가를 요청하는 메시지

## 트랜잭션 아웃박스 패턴

<aside>
💡

</aside>

위 방식을 사용해도 메시징 시스템 연동 실패 가능

메시지 데이터를 DB에 보관하는 방식 → 트랜잭션 내에서 DB 변경 작업 + 아웃박스 테이블에 메시지 추가

아웃박스 패턴을 사용하면 메시지 유실 X, 롤백 시 같이 롤백되어 잘못된 데이터 전송 X

**발송 완료 표기 방법**

- 발송 대기 / 완료 / 실패 상태 저장
- 성공적으로 전송한 마지막 메시지의 ID 별도 기록

## 배치 전송

**프로세스**

```
1. DB에서 전송할 데이터 조회
2. 조회한 결과를 파일로 기록
3. 파일을 연동 시스템에 전송
```

**파일 형식**

- 값1(구분자)값2(구분자) … → 구현 간단, 파싱 속도 빠름
- 이름1=값1 이름2=값2 … → 위치에 관계없이 값 파악 가능, 1번 형식에 비해 용량이 큼
- JSON 문자열 → 대부분 변환 기능을 제공해 쉽게 구현 가능, 데이터 크기가 큼

+ 송수신 주체, 시간, 경로 설정 필요

재처리 기능 → 배치 처리 일정 시간 이후 재전송하는 기능 구현

## CDC

변경된 데이터를 추적하고 판별해 변경된 데이터로 작업을 수행할 수 있도록 하는 설계 패턴

DB는 커밋된 데이터만 CDC에 순서에 맞게 전달 (레코드 단위)

CDC는 변경 데이터 확인/가공 후 대상 시스템에 전파

- 변경 데이터 그대로 전파
- 변경 데이터를 가공/변화해서 전파

두 시스템 간 데이터 동기화 목적 → DB와 DB 사이에 CDC를 두어 복제

메시징 시스템에 데이터를 전파 → 여러 시스템에 변경된 데이터를 둘 수 있어 확장에 유리

** CDC 처리기는 변경 데이터를 어디까지 처리했는지 기록 필요

      → 기록하지 않을 시 마지막 로그 데이터부터 읽어야하는데 이 시간동안의 변경 데이터를 놓침

** CDC는 코드 수정 없이 타 시스템에 관련 데이터를 전파할 수 있음

** CDC는 DB에 변경이 생기면 그걸 자동으로 감지해서 Kafka로 보내줌

# [동시성] 잠금, 원자적 타입 해결

초당 0.1초가 걸리는 100개의 요청이 온다고 가정했을 때 1초 안에 처리하기 위해서는 0.1초에 10개의 요청을 처리해야 함

순서대로 처리한다면 100개의 요청을 처리하는데 10초가 걸림 → TPS가 100에서 10으로 크게 저하

### 클라이언트 요청마다 스레드를 할당해서 처리

요청마다 스레드를 할당 해 여러 스레드가 동시에 코드를 실행하도록 함 → 동시 요청 개수만큼 스레드가 동시에 실행

동시 실행을 고려하지 않고 코드를 작성할 시 찾기 어려운 버그가 생길 수 있음

```jsx
public class Inteaser {
	private int count = 0;
	public void inc() { count = count + 1; }
	public int getCount() { return count; }
}
```

위의 코드를 여러 개의 스레드에서 돌린다고 가정 → 동시에 여러 스레드가 count = count + 1 코드를 실행했을 때 6 → 8이 되어야 하는데 6 → 7이 될 수 있음

** 경쟁 상태 → 여러 스레드가 공유 자원에 접근할 때 접근 순서에 따라 결과가 달라지는 상황 

```jsx
public class PayService {
	private Long payId;
	
	public PayResp pay(PayRequest req) {
		this.payId = getPayId();
		saveTemp(this.payId, req);
		PayResp resp = sendPayData(this.payId, ...);
		applyResponse(resp); → { PayData payData = createPayData(resp); updatePayData(this.payId, payData); }
		return resp;
	}
}
```

다음과 같은 코드에서 만약 PayService가 싱글톤 객체 상황이라면 다중 스레드 환경에서 동시 사용시 값이 달라질 수 있음

```jsx
스레드 1 - payId를 1로 생성                                                    → updatePayData(payId, payData)
스레드 2 -                  → payId를 2로 생성 → updatePayData(payId, payData)
							payId : 1         payId : 2               payId : 2                        payId : 2
```

스레드 1에서 사용하던 payId에 대한 데이터가 스레드 2의 데이터로 덮어씌워지게 되면서 스레드 1은 올바르지 않은 데이터를 수정하게 됨

마찬가지로, DB도 동시에 데이터를 변경하게 되면 동시성 문제가 발생할 수 있음

** 싱글톤 패턴 → 싱글톤 패턴은 객체 지향 프로그래밍에서 특정 클래스가 단 하나만의 인스턴스를 생성하여 사용하기 위한 패턴

인스턴스를 여러개 만들면서 생기는 불필요한 자원 낭비나 예상치 못한 결과를 방지하기 위해 단 한 번 생성 후 전역에서 객체를 공유 사용

단, 내부에 상태값(멤버 변수)을 가지고 있으면 스레드 간 공유되므로 상태를 변경하지 않거나 불변객체로 유지해야 함

## 프로세스 수준에서 동시 접근 제어

단일 프로세스 내에서 동시성을 다룰 때 필요한 기초 개념

### 잠금(lock)을 이용한 접근 제어

공유 자원에 접근하는 스레드를 한 번에 하나로 제한

1. 잠금 획득
2. 공유 자원에 접근 (임계 영역 → 동시에 둘 이상의 스레드나 프로세스가 접근하면 안되는 공유 자원에 접근하는 코드 영역)
3. 잠금 해제

→ 여러 스레드에서 동시에 잠금 획득을 시도할 시 하나만 획득하고 나머지는 대기 상태

** Java synchronized vs ReentrantLock

synchronized → 간단하게 동시 접근 제어 가능 (코드 블록 종료 시 자동 잠금 해제)

ReentrantLock → 잠금 획득 대기 시간 등 synchronized에서 지원하지 않는 기능 제공

UserSessions가 동시성 문제가 없는지 확인하기 위한 테스트

→ lock을 사용해 500개의 데이터를 넣게 되면 객체가 정상적으로 추가된 것을 확인할 수 있음

→ lock을 사용하지 않고 500개의 데이터를 넣게 되면 객체가 없다는 에러가 나는 것을 확인할 수 있음

** Mutex → mutual exclusion의 줄임말, 프로그래밍 언어에 따라 Lock 또는 Mutex 언어를 사용

ReentrantLock의 경우 한 번에 하나의 스레드만 잠금을 획득할 수 있음 → 나머지 스레드는 잠금 해제될 때까지 대기

따라서 잠금 이외에도 동시 접근 제어를 위한 구성요소 존재

잠금은 안전하지만 성능에 영향을 줄 수 있으므로 임계 구역을 최소화해야 함

### 세마포어

동시에 실행할 수 있는 스레드 수 제한 → 자원에 대한 접근을 일정 수준으로 제한하고 싶다면 세마포어 사용 가능 (자바에서는 구현체를 permit / Go에서는 weight으로 표현)

1. 세마포어에서 퍼밋 획득 (퍼밋 개수 - 1)
2. 코드 실행
3. 세마포어에 퍼밋 반환 (퍼밋 개수 + 1)

→ 더이상 세마포어에 사용할 수 있는 퍼밋이 없다면 스레드들은 다른 스레드가 퍼밋을 반환할 때까지 대기

세마포어는 "동시 접근 허용 개수"를 제어하고 싶을 때 사용, lock은 "1개만 접근 허용"일 때 사용

### 읽기 쓰기 잠금

UserSessions가 동시성 문제가 없는지 확인하기 위한 테스트에서 HashMap의 데이터를 get(), put() 할 때 둘 다 lock을 걸게 된다면

get()을 실행하는 동안 put()을 사용해 HashMap이 변경되지만 않는다면 문제 X, get + put 동시 실행 X, get만 동시 실행 O

get, put 모두 잠금을 걸어두면 get 실행시에도 한 스레드만 읽기가 가능 해 읽기 성능이 떨어짐

- 쓰기 잠금은 한 번에 한 스레드만 구할 수 있음
- 읽기 잠금은 한번에 여러 스레드를 구할 수 있음
- 한 스레드가 쓰기 잠금을 획득했다면 쓰기 잠금이 해제될 때까지 읽기 잠금을 구할 수 없음
- 읽기 스레드가 획득한 모든 스레드가 읽기 잠금을 해제할 때까지 쓰기 잠금을 구할 수 없음

→ ReentrantReadWriteLock을 사용하면 읽기/쓰기 잠금을 구분해서 처리 가능

### 원자적 타입 (Atomic Type)

```java
public class Inteaser {
	private int count = 0;
	public void inc() { count = count + 1; }
	public int getCount() { return count; }
}
```

이 코드에서 inc() 시 락을 걸게되면 동시성 문제를 해결할 수 있지만 CPU 효율이 떨어짐

→ 자바에서 AtomicInteger / AtomicLong / AtomicBoolean과 같은 원자적 타입을 사용해 다중 스레드 환경에서 동시성 문제 없이 데이터 변경이 가능

내부에서 Compare And Swap 연산 실행 

** **Compare And Swap**

1. 멀티스레드, 멀티코어 환경의 경우 각 변수를 스레드 내의 스택(캐시)에 저장
2. 변수에 대해서 변경 시 스레드 저장 값과 메인 메모리 저장값 비교
3. 값이 같다면 치환 / 다르다면 계속 재시도

→ 락보다 빠르지만 재시도가 많아질 경우 오히려 비용이 커질 수 있음

### 동시성 지원 컬렉션

HashMap, HashSet은 동시성 문제 발생

→ Collections 클래스의 경우 동기화된 컬렉션을 생성하는 synchronizedMap 메서드 제공

→ 동시성 자체를 지원하는 ConcurrentHashMap 등 사용

동시성 문제를 해결하기 위해 불변값 사용 가능

** 불변값 → 바뀌지 않는 값, 데이터 변경이 필요한 경우 기존 값 수정 X, 새로운 값을 생성해 사용

## [동시성] DB와 동시성

DB 트랜잭션은 여러 개의 조회나 쓰기를 논리적으로 하나의 연산으로 묶어줌 (커밋, 롤백) → 트랜잭션만으로는 동시성 문제 해결 X

- 선점 잠금 → 동일한 레코드에 대해 한 번에 하나의 트랜잭션만 접근할 수 있도록 제어
- 비선점 잠금 / 낙관적 잠금 → 값을 비교해서 수정하는 방식, 쿼리 실행 자체는 막지 않으면서 데이터의 잘못된 변경 방지

### 선점 잠금 (비관적 잠금)

데이터에 먼저 접근한 트랜잭션이 잠금을 획득하는 방식

```
트랜잭션 1 - select * from A where id = 1 for update → update A ... → 커밋
트랜잭션 2 -          select * from A where id = 1 for update              → update A ... → 커밋
                트랜잭션 1 lock 획득                                       → 트랜잭션 2 lock 획득
```

→ 동시에 같은 데이터를 수정하면서 데이터 일관성이 깨지는 것을 방지

** 분산 잠금→ 여러 프로세스가 동시에 동일한 자원에 접근하지 못하도록 막는 방법, 여러 프로세스 간 잠금 처리를 함 (레디스로도 빠르게 적용 가능) 

### 비선점 잠금 (낙관적 잠금)

명시적으로 잠금을 사용하지 않고, 데이터를 조회한 시점의 값과 수정하려는 시점의 값이 같은지 비교하는 방식

→ 보통 version 컬럼을 사용해 비선점 잠금 구현

```
1. select 쿼리 실행 시 version 컬럼 함께조회
2. 로직 수행
3. update 쿼리 실행 시 version 컬럼 + 1, version 컬럼 값이 1에서 조회한 값과 같은지 비교하는 조건을 where 절에 추가
4. update 결과로 변경된 행 개수가 0이면 다른 트랜잭션에서 값을 변경한 것임으로 트랜잭션 롤백
5. update 결과로 변경된 행 개수가 0보다 크면 다른 트랜잭션보다 먼저 값을 변경한 것임으로 트랜잭션 커밋 
```

→ 일단 데이터 변경을 시도해 선점 잠금과 비교했을 때 대기 과정이 없어 실패 시 빠르게 결과를 응답할 수 있음

### 외부 연동과 잠금

트랜잭션 범위 내에서 외부 시스템과 연동해야 한다면 비선점 잠금보다는 선점 잠금 추천

→ 주문 취소 과정에서 외부 PG 시스템 호출해서 결제까지 함께 취소한다고 가정

- 비선점 잠금 - 결제는 이미 취소되었는데 상태가 주문 시작이라서 롤백할 수도 있음 → 트랜잭션 아웃박스 패턴을 통해 처리할 수도 있음

### 증분 쿼리

```
1. 주제 조회
2. 참여 데이터 추가
3. subject.getCount() + 1을 통해 주제 데이터 참여자 수 증가
```

→ 여러 개의 사용자가 동시에 실행하게 되면 1만 증가하는 문제 발생 가능

→ 선점 방식을 사용할 수도 있지만, joinCount = joinCount + 1을 통해 순차적으로 실행하게 할 수도 있음

** 항상 원자적 연산이 아닐 수도 있기 때문에 검증 과정 필요

## 주의사항

### 잠금 해제

잠금을 획득한 후에는 반드시 해제하는 과정이 필요 → 잠금을 시도하는 스레드가 무한정 대기할 수도 있음

세마포어도 퍼밋 획득 후 반드시 반환하는 과정이 필요

### 대기 시간 지정

동시 접근이 많아지게 되면 잠금 획득을 위해 대기하는 시간이 길어질 수 있음 → 대기 시간 지정

`tryLock(시간, 시간타입)`을 통해 일정 시간 동안 잠금을 획득하지 못한다면 실패 처리

`tryLock()`을 통해 대기 시간 없이 바로 결과를 반환할 수도 있음

→ 사용자에게 빠르게 응답함으로 불안감 감소

### 교착 상태 피하기

교착 상태 → 2개 이상의 스레드가 서로가 획득한 잠금을 대기하면서 무한히 기다리는 상황

```
스레드 1 - 자원 A 잠금 획득 → 자원 B 잠금 대기
스레드 2 - 자원 B 잠금 획득 → 자원 A 잠금 대기
```

→ 서로가 서로의 잠금이 필요해 무한정으로 대기하게 됨

**해결 방법**

1. 잠금 대기 시간 제한 → 무한정 대기하지 않고 일정 시간이 지나면 실패하면서 교착 상태를 풀 수 있음
2. 지정한 순서대로 잠금 획득 → 두 스레드 모두 자원 A에 대해 잠금을 시도하고 B에 대해 잠금을 시도하도록 설정해 교착 상태가 일어나지 않도록 할 수 있음

** 라이브락 → 활동을 하는 것 같지만 실제로는 아무것도 하지 않는 상태 (우선순위를 두거나 임의성을 주는 방식으로 해결 가능)

** 기아 상태 → 우선 순위가 높은 작업이 많아 낮은 작업이 실행이 안 되는 상황 (실행 안되는 작업의 우선순위를 높이거나 공유 자원 독점 시간에 제한을 두는 방식으로 해결 가능)

## 단일 스레드로 처리

동시성 문제의 주된 원인 → 여러 스레드가 동시에 동일한 자원에 접근하기 때문에

→ 애초에 한 스레드로만 처리 해 동시성 해결

```
작업 요청 스레드 1 --|
작업 요청 스레드 2 --|-- 작업 큐 -- 상태 관리 스레드
작업 요청 스레드 3 --|
```

→ 데이터 변경이나 접근이 필요한 스레드는 작업 큐에 작업을 넣기만 하고 직접 상태에 접근 불가

→ 상태 관리 스레드는 작업 큐에서 작업을 꺼내어 필요한 작업을 순차적으로 수행 → 잠금과 같은 수단이 필요 없어 코드가 단순해짐

두 스레드가 데이터 공유가 필요하다면 콜백이나 큐와 같은 수단을 사용해 복제본 공유 또는 불변 값 공유 → 다른 스레드에서 원본 데이터를 수정하지 못하도록 해 동시성 문제 방지

** Go에서는 여러 고루틴이 동시에 접근하는 것을 막기 위해 잠금 수단을 제공하지만 채널을 통해 고루틴을 공유하는 방식 권장

단일 스레드로 처리하면 동시성 문제는 해결 → 구조가 복잡해지는 단점 (논블로킹이나 비동기IO 사용하는 경우 블로킹 연산을 최소화해야 해 단일 스레드 방식이 적합)

** 성능→ 임계 영역 실행시간이 짧고 동시 접근 스레드 수가 적으면 Lock 유리, 동시 실행이 많고 임계 영역 실행이 길면 Queue나 Channel 방식 유리

# [I/O 병목] 가상 스레드, 논블로킹

많은 서버는 HTTP 프로토콜을 이용, 데이터 처리를 위해 DB는 TCP에 기반한 프로토콜을 사용, 레디스 사용시에도 네트워크를 통해 데이터를 주고받음

네트워크를 통해 데이터를 주고 받는 과정은 outputStream.write() + inputStream.read() 두 단계를 실행

```
스레드 - 코드 실행 → write 시작          → write 리턴 → 코드 실행 → read 시작          → read 리턴 → 코드 실행
	                    스레드 대기                                  스레드 대기
```

→ read와 write를 실행하는 동안 스레드는 아무 작업도 하지 않고 입출력이 끝나기까지 기다려야 함 (블로킹 됨) → 네트워크 연동이 많은 경우 입출력이 전체 실행 시간의 90% 이상을 차지할 수 있음

** 블로킹 → 작업이 완료될 때까지 스레드가 대기하는 것, 입출력 과정에서 블로킹이 발생하는 방식을 블로킹 IO라고도 함

대기하는 스레드가 생긴다 = 그 시간만큼 CPU가 아무 것도 하지 않는다

- 요청 당 스레드 할당 방식의 문제점
    - 스레드는 수백 KB~수 MB 메모리를 사용. 예: 1만 명 동시 연결 시 메모리 수십 GB 필요
    - 많은 스레드가 동시에 컨텍스트 스위칭을 하면 CPU 효율 저하
    - 요청당 스레드 방식은 IO 대기, 컨텍스트 스위칭, 메모리 낭비를 초래 → 빈번하면 CPU가 실제 작업보다 스케줄링에 더 많은 시간을 쓰게 됨

** 컨텍스트 스위칭 → 스레드의 상태 정보를 변경하고 스레드를 전환하는 과정 (여러 스레드가 일정 시간 동안만 CPU에서 실행되고 다음 스레드로 전환, CPU는 실질적인 작업을 하지 않음)

위와 같은 방식으로 처리량을 늘리는 방식이 아닌 자원 효율을 높이는 방식

- 가상 스레드나 고루틴 같은 경량 스레드 사용
- 논블로킹 또는 비동기 IO 사용

** 처음부터 위와 같은 방식을 적용 X → 트래픽이 증가하거나 높을거라 예상되는 경우에만 적용

## 가상 스레드

입출력 동안 스레드가 대기하지 않고 다른 일을 할 수 있는 방식 → 경량 스레드로 OS가 관리하는것이 아니라 런타임이 관리하는 스레드

```
OS  -  OS 스레드 1    OS 스레드 2     OS 스레드 3                플랫폼 스레드: OS가 스케줄링하는 스레드
JVM - 플랫폼 스레드 1  플랫폼 스레드 2  플랫폼 스레드 3               가상 스레드: 런타임(예: JVM)이 관리하는 경량 스레드
		  |       |                       |                     캐리어 스레드(carrier thread): 가상 스레드를 실제로 실행하는 플랫폼 스레드
가상 스레드 1  가상 스레드 2 가상 스레드 3 가상 스레드 4               마운트/언마운트: 가상 스레드가 플랫폼 스레드에 연결/해제되는 과정
```

→ OS 스케줄러에 의해 스레드가 번갈아 가면서 실행 → JVM 스케줄러에 의해 가상 스레드를 번갈아 가면서 실행 (스케줄러 풀 기본값은 CPU 코어 개수, 필요에 따라 증가)

### 플랫폼 스레드 vs 가상 스레드

플랫폼 스레드

- 1만 개의 플랫폼 스레드 생성, 스레드 기본 스택 크기가 1mb → 약 9.8gb의 메모리 사용 (예약한 메모리 기준)
- 10만 개의 플랫폼 스레드를 생성하는데 21,467ms 소요

가상 스레드

- 1만 개의 가상 스레드 생성, 1개의 스레드가 평균 2kb 메모리 사용 → 약 20mb의 힙메모리 사용 + 스케줄링을 위한 플랫폼 스레드 8mb = 약 28mb
- 10만 개의 플랫폼 스레드를 생성하는데 196ms 소요

** 가상 스레드는 호출 스택의 깊이에 따라 사용하는 메모리를 동적으로 늘렸다가 줄임

** 캐리어 스레드 - 가상 스레드를 실행하는 플랫폼 스레드, 마운트 - 가상 스레드가 특정 플랫폼 스레드에 연결 (반대는 언마운트)

### 네트워크 IO와 가상 스레드

가상 스레드는 실행하는 과정에서 블로킹되면 플랫폼 스레드와 언마운트되고 실행이 멈춤

** 블로킹 연산 → IO 기능, ReentrantLock, Thread.sleep() 등… → 가상 스레드가 블로킹 되면 플랫폼 스레드는 대기 중인 다른 스레드 실행

** synchronized는 자바 23 또는 이전 버전에서 블로킹 되면 언마운트 되지 않고 플랫폼 스레드까지 블로킹 됨 → 고정, 이 경우 CPU 효율을 높일 수 없음

### 가상 스레드와 성능

네트워크 프로그래밍 같이 입출력이 주를 이루는 작업 IO 중심 작업 / 정렬처럼 계산이 추를 이루는 작업 CPU 중심 작업

가상 스레드는 IO 중심 작업일 때 효과가 있음 

→ IO 중심 작업인 경우 플랫폼 스레드가 CPU 낭비 없이 효율적으로 가상 스레드 실행 가능

→ 플랫폼 스레드 개수 < 가상 스레드 개수 → 플랫폼 스레드 개수가 더 적을 경우 다른 가상 스레드를 찾아야 해 이점이 떨어짐

→ 가상 스레드의 이점을 얻으려면 CPU 코어 수를 줄이거나 트래픽이 더 많아야 함 → 처리량을 높일 수 있음, 실행 속도를 높이는 게 아님!

CPU 중심 작업서는 성능이 오히려 나빠질 수 있음 

→ 블로킹 연산이 없는 경우 플랫폼 스레드는 하나의 가상 스레드만 실행하게 되어 동시 실행 효과 X

** 대부분의 서버는 스레드를 미리 생성해 요청시 사용하는 스레드 풀 사용, 가상 스레드는 생성 비용이 크지 않기 때문에 스레드 풀을 미리 구성할 필요가 없음

### 가상 스레드의 장단점

**장점**

- 기존 코드를 크게 수정할 필요가 없음
    
    → 대부분의 프레임워크나 라이브러리에서 지원, 기존 코드를 그대로 유지하면서도 가상 스레드를 사용해 성능을 높일 수 있음
    
- 스레드 생성/관리 비용이 낮아 대량 동시 연결 처리에 유리

**단점**

- 무제한으로 늘리면 메모리·스케줄링 오버헤드가 생김 (가상 스레드도 메모리·스케줄링 자원 소모)
- CPU 중심 작업에서는 오히려 성능 저하 가능

## 논블로킹 IO로 성능 높이기

가상 스레드를 통해 처리량을 높일 수 있지만 결국 메모리를 사용하고 스케줄링이 필요해 많아질 수록 더 많은 메모리를 차지하고 스케줄링에 더 많은 시간을 사용

→ 트래픽이 폭발적으로 증가하게 되면 경량 스레드로도 한계가 올 수 있음 → 논블로킹 IO 사용 필요

### 논블로킹 IO 동작 방식

논블로킹 IO는 입출력이 끝날 때까지 대기하지 않음 → 데이터 조회 여부와 상관 없이 대기하지 않고 바로 다음 코드를 실행

```java
while (true) {
	int byteReads = channel.read(buffer);
	if (byteReads > 0) { handleData(channel, buffer); }
}
```

→ 위 코드의 경우 읽은 데이터가 없어도 while 루프가 무한 반복되어 CPU 낭비가 심함

실제 논블로킹 IO는

1. 실행 가능한 IO 연산 목록을 구함
2. 1에서 구한 IO 연산 목록을 차례로 순회하며 처리
3. 반복

블로킹 IO의 경우 요청 별로 스레드를 할당

논블로킹 IO의 경우 요청 수에 상관없이 일정량의 스레드 개수를 유지해 같은 메모리로 더 많은 요청 처리 가능

하지만, 1개의 스레드만 사용할 경우 동시성이 떨어져 보통 채널을 N개 그룹으로 나누고 각 그룹마다 스레드를 생성하는 방식 사용 (보통 CPU 개수만큼 그룹을 나눔)

** IO 멀티플렉싱 → 단일 이벤트 루프에서 여러 IO 작업을 처리하는 방식 (Linux epoll, Window IOCP …), 더 적은 자원으로 더 많은 요청 처리 가능

### 리액터 패턴

동시에 들어오는 여러 이벤트를 처리하기 위한 이벤트 처리 방법 

- 리액터 → 이벤트가 발생할 때까지 대기하다가 이벤트가 발생하면 알맞은 핸들러에 이벤트 전송
- 핸들러 → 받은 이벤트에 대해 실제 비즈니스 로직 수행

→ 리액터는 이벤트를 대기하고 핸들러에 전달하는 과정을 반복해 이벤트 루프라고도 부름 (Netty, Nginx, Node.js …)

리액터 패턴에서는 이벤트 루프를 단일 스레드로 실행하는데 이는 처리량을 최대로 못 내거나 핸들러에서 CPU 연산이나 블로킹을 유발할 경우 전체 이벤트 시간이 지연될 수도 있음

→ 핸들러나 블로킹 연산은 별도 스레드 풀에서 사용하는 방식으로 처리

리액트 네트와 같은 프레임워크를 사용해 논블로킹 IO를 쉽게 구현하는 것 시도 추천

### 논블로킹/비동기 IO 성능

작가의 테스트 결과

- 간단한 푸시 서버 (자바, 힙 메모리 1.5gb 할당) - 블로킹 IO 최대 6,000 동접수 / 논블로킹 IO 최대 120,000 동접수
- 간단한 푸시 서버 - 고언어 최대 20,000 동접수 /  gnet 프레임워크 사용 최대 180,000 동접수

논블로킹 IO나 가상 스레드 적용시 검토할 사항

- 문제가 있는가 → 성능 문제가 없거나 트래픽 증가 가능성이 없다면 검토할 필요가 없음
- 문제가 네트워크 IO 관련 성능 문제인가 → 트래픽은 그대로인데 DB 쿼리 시간의 증가일 경우 적용해도 시간 변화 X
- 구현 변경이 가능한가 → 문제가 네트워크 IO 관련이라면 적용 검토 필요, 적용이 불가능하다면 멜모리를 늘리거나 수평 확장을 통해 완화
    
    → 우선순위에 밀리거나 기술에 대한 익숙함이 부족한 경우에도 구현 변경이 불가능 할 수 있음

# [암호화] 암호화 종류, 트래킹

실제 K사에서 `https://주소/…?cd=고객코드` → 사용자 검증을 하지 않고 해당하는 고객 정보를 응답해 해커가 1천만 건의 데이터를 탈취함

## 인증과 인가

인증 (Authentication) → 사용자가 누구인지를 확인하는 과정 (로그인, SSO 등)

인가 (Authorization) → 인증된 사용자가 특정 자원에 접근할 권한이 있는지 결정하는 과정

## 인증과 토큰

사용자가 누구인지 확인하는 데 성공하면 서버는 클라이언트에게 문자열로 된 토큰 제공 → 이후 요청은 토큰을 사용해 누구인지를 증명

토큰을 이용해 사용자를 식별하기 위해서는 토큰 ↔ 사용자 간의 매핑 정보를 저장해야 함

- 서버의 별도 저장소 → 별도 저장소에 토큰과 사용자 식별 정보 저장
- 토큰 → 토큰 자체에 사용자 식별자 정보 저장

### **별도 저장소에 토큰과 사용자 식별 정보 저장**

1. DB나 레디스와 같은 별도 저장소에 보관
    
    → 로그인 성공 시 임이의 토큰 문자열을 만들어 외부 저장소에 `{token -> userId, createdAt, lastUsedAt, ttl}` 형태로 저장 (중복 토큰 값이 생기지 않도록 주의)
    
    → 토큰, 사용자 식별자, 생성 시간, 최근 사용 시간 등의 데이터를 가짐
    
2. 서버 메모리에 토큰 데이터 저장 (서블릿 세션 …)
    
    → 서블릿 세션은 세션 생성 시 고유한 ID를 생성하는데 이를 토큰으로 사용 가능
    
    단, 서버가 여러 대인 경우 각 서버는 고유한 세션을 가지므로 고정 세션이 필요
    
    세션의 경우 서버 재시작 시 데이터가 사라지고, 세션의 개수가 메모리 크기의 제한을 받음 (세션 데이터를 별도 저장소에 보관하기도 함)
    

→ 서버에서 중앙 제어(무효화, 강제 로그아웃) 가능하지만, 상태 저장(stateful)으로 수평 확장/관리 필요

### **토큰 자체에 사용자 식별자 정보 저장**

1. JWT 이용
    
    → 사용자 식별자를 payload로 가지는 JWT를 생성해 클라이언트가 사용
    
    → 토큰만 있으면 사용자가 누구인지 확인할 수 있고, 외부 DB에 저장할 필요가 없어 서버 구조가 간단하고 메모리에 저장하지 않아 수평 확장이 용이
    
    → 토큰 안에 데이터가 추가되어 서버와 클라이언트가 주고 받는 데이터의 크기가 커져 트래픽이 증가
    
    → 클라이언트에 토큰 데이터가 저장되므로 서버에서 제어할 수 없음
    

→ 서버에서 매번 저장하지 않아도 되고 stateless 하며 수평 확장에 유리하지만, 토큰 자체가 유효한 한 서버에서 차단하기 어려움, 네트워크 부담, 민감한 정보는 토큰에 담지 말 것

### **토큰을 클라이언트에서 서버로 전송할 때 사용하는 방식**

1. 쿠키 → 쿠키를 사용해 토큰 전송
    
    → 서버가 전송한 모든 쿠키를 웹 브라우저는 모든 요청에 포함시켜 전송해 별도의 js 코드 작성 필요 없음
    
2. 헤더 → 특정 이름을 가지는 헤더를 사용해 토큰 전송
    
    → Authorization과 같은 헤더에 토큰을 담아 전송
    

### **토큰 보안**

서버 보안이 철저해도 클라이언트 보안이 취약하게 되면 토큰이 탈취될 수도 있고, 탈취한 클라이언트는 본 소유자인 것처럼 행동 가능

유효시간 제한 → 최초 생성 시 유효시간을 두고, 시간이 지나면 사용자에 대한 접근 거부

- 토큰 생성 시점 기준 제한 → 9:00 토큰 생성, 유효시간 1시간 → 10:00에 토큰 만료
- 마지막 접근 시간 기준 유효시간 설정 → 9:00 토큰 생성, 유효시간 1시간 → 9:59 마지막 접근 → 10:59 토큰 만료 시간

- **짧은 액세스 토큰 + 리프레시 토큰** 패턴 → 액세스 토큰은 짧게(몇 분~몇 시간), 리프레시 토큰은 더 길게(안전하게 관리) 발급, 리프레시 토큰으로 액세스 토큰 재발급
- **토큰 무효화(로그아웃/강제 차단)** → 상태 저장 방식은 저장소에서 삭제, JWT 등 stateless 방식은 토큰 블랙리스트(레디스)나 키 회전으로 대응
- **토큰 바인딩 →** 유효시간 + 클라이언트 IP를 비교하여 토큰 보안을 향상
- **HTTPS 사용 필수** → 전송 중 중간자 공격(MITM) 방지

** MITM → 클라이언트와 서버 사이의 통신을 **가로채서 엿보거나 변조하는 공격** `A(클라이언트) ↔ **[공격자]** ↔ B(서버)`

## 인가와 접근 제어 모델

K 서비스의 정보 유출 이슈의 경우 본인만 정보를 조회할 수 있도록 제어했어야 하는데 로그인 여부만 확인해서 생긴 문제

→ 접근 제어의 기본은 사용자를 토큰이나 세션으로 식별, 파라미터만으로 로그인한 사용자의 식별자를 구하면 안 됨

### 접근 제어 모델

→ 사용자가 접근할 수 있는 기능이나 자원을 관리하기 위한 모델 (RBAC 구조)

- 역할별 권한 부여 (RBAC 구조)
    
    → 사용자에게 역할을 부여해 권한을 가지도록 함
    
    → 역할을 체계적으로 관리하고, 권한을 일일이 부여하지 않아도 돼 관리가 용이 / 역할을 무분별하게 정의하면 역할이 불필요하게 늘어나고 관리가 복잡해짐
    
- 사용자별 권한 부여 (ABAC 구조)
    
    → 각 사용자에게 직접 권한을 가지도록 함
    
    → 시스템 규모가 작거나 역할을 나누기 애매할 때 적합, 구현이 단순
    
- 속성별 권한 부여
    
    → IP와 같은 고유 속성을 통해 권한을 부여하거나 제한
    
    → 보다 정교한 접근 제어가 가능하지만, 구현이 복잡하고 사용할 수 있는 속성과 규칙 정의에도 많은 시간 소요
    

** 운영 계정을 공유하게 되면 누가 어떤 것을 했는지 식별할 수 없어 책임 소재 파악 불가 → 운영자마다 별도의 계정을 발급해 추적을 가능하게 해야함

## 데이터 암호화

로그인에 사용하는 비밀번호는 보통 다른 서비스에서도 동일하게 사용해 유출되면 다른 서비스까지 위험해짐 → 비밀번호는 암호화 해 저장해야 함

## 단방향 암호화

암호화한 데이터를 복호화할 수 없는 방식 (SHA-256, MD5, BCrypt …)

원본데이터가 조금만 달라도 완전히 다른 해시값 생성

실제 암호화는 바이트 데이터를 기준으로 동작해 반환된 바이트 배열을 16진수나 Base64 표기법을 사용해 문자열로 표현

** 해시는 원본 데이터와 상관 없이 일정한 길이의 해시 값을 생성해 충돌이 일어날 수 있음 → 해시 함수 결과가 길 수록 충돌 가능성 감소

### **값 비교**

해시 함수로 생성한 해시 값이 암호화 된 값과 같다면 두 데이터가 같다고 간주 `hash(input + salt) == stored_hash`

단, 원본 데이터로 복호화 할 수 없어 기존 비밀번호를 알려주는 등의 기능은 구현할 수 없음

### **솔트**

같은 해시 알고리즘을 사용하게 되면 동일한 데이터에 대해서는 동일한 해시 값이 생성되어 유출 시 레인보우 테이블을 통해 원본 데이터를 유추할 수 있음

항상 같은 값을 생성하는 해시의 특징은 보안을 취약하게 해 원문에 salt 값을 더 해 취약점을 보안할 수 있음 → 솔트 값을 모르면 원본 추측이 어려움

** 레인보우 테이블 → 문자열과 해시 값을 미리 계산한 표

## 양방향 암호화

암호화와 복호화가 모두 가능한 방식 (AES, RSA …)

### **대칭키 암호화**

암호화와 복호화할 떄 동일한 키를 사용 → 키가 유출되면 누구나 암호화된 데이터를 복호화 할 수 있어 키의 보안이 중요

### AES 암호화 방식

```
**암호화 과정**
1. 키 생성 → 암호화와 복호화에서 동일하게 사용
2. 평문 준비 → 바이트 단위 준비, 블록 크기는 16바이트 고정, 패딩 추가
3. 초기화 벡터 설정 → CBC, CFB 모드의 경우 첫 블록 암호화를 위해 IV 필요
4. 암호화 수행
5. 암호문 생성 → 암호화 결과를 Base64로 인코딩 해 저장하거나 전송

**복호화 과정**
1. 암호문 디코딩
2. IV를 읽어 동일하게 세팅
3. AES 복호화
4. 패딩 제거
5. 평문 복원
```

### **비대칭 키 암호화**

암호화와 복호화할 때 서로 다른 키 사용 → 공개키와 개인키를 생성 해 사용

```
암호화 과정
1. 공개키와 개인키 한 쌍 생성 → 클라이언트에게 공개키 전달
2. 공개키로 암호화 수행 → 공개키로 암호화 된 데이터는 개인키로만 복호화 가능
- 클 → 서 - 클라이언트는 공개키로 암호화 해 전송, 서버는 개인키로 복호화
- 서 → 클 - 서버는 개인키로 암호화 해 전송, 클라이언트는 공개키로 복호화 (암호화보다는 전자서명 개념)

복호화 과정
1. 자신만 가진 개인키로 암호화 된 데이터를 원본 평문으로 복호화
```

## HMAC을 이용한 데이터 검증

HMAC → 메시지가 위변조되지 않앗다는 것을 확인할 수단, 메시지의 무결성과 인증을 보장하기 위해 사용하는 암호화 기술

- 메시지 무결성 → 메시지가 중간에 위변조되지 않음
- 인증 → 메시지 발신자를 인증할 수 있음

HMAC은 발신자와 수신자만 알고있는 비밀키를 공유해 비밀키로 해싱한 MAC을 원본 메시지와 함께 전송하고, 수신자는 비밀키를 이용해 MAC을 다시 생성한 후 서로의 MAC 비교

같으면 메시지가 변경되지 않았음을 의미, 다르면 메시지가 변경되었음을 의미

HMAC 방식은 단순하고 효율적임 → 비밀 키만 공유하면 MAC을 생성할 수 있어 낮은 비용으로 인증 보안 구현

단, 키가 유출되면 보안에 취약해지고, 유출 위험이 있는 만큼 비밀 키 교체도 까다로울 수 있음

## 방화벽으로 필요한 트래픽만 허용

필요한 만큼만 네트워크 접근을 허용하고 나머지는 차단 → 물리적인 장비 / 가상 방화벽

- 인바운드 트래픽 → 외부에서 내부로 유입되는 네트워크 통신
    
    → 필수 트래픽만 허용하고 나머지는 차단할 것을 권장
    
    → 서비스 API - 모든 IP에서 서버의 443 포트로 접근 가능 / 관리자 API - 사내 IP에서 서버의 443 포트로 접근 가능
    
- 아웃바운드 트래픽 → 내부에서 외부로 유출되는 트래픽
    
    → 필수 트래픽만 허용하고 나머지는 차단할 것을 권장
    

방화벽은 단순 트래픽 제어 뿐만 아니라 DDoS나 포트 스캔 같은 네트워크 공격을 차단할 수 있음

웹 방화벽 사용시 SQL 인젝션, XSS 같은 HTTP/HTTPS 수준 발생 공격 방어가 가능

개별 서버 자체도 방화벽 기능을 통해 트래픽 제어가 가능

** DDoS → 여러 위치에서 동시에 다량의 트래픽을 보내 서버를 느리게 하거나 중단시키는 공격

## 감사 로그 남기기 (audit log)

특정 작업, 절차, 사건 또는 장치에 영향을 주는 활동의 순서를 입증하는 보안 관련 기록

- 사용자의 로그인/로그아웃 기록
- 암호 초기화 등 설정 변경 내역
- 환자 기록을 조회한 의료진 정보
- 계약서 수정 이력

보안 시스템에서 사고 발생 시 활동을 입증하는 증거로 사용됨

** 감사 로그는 컴플라이언스나 정책을 지키기 위한 목적, 정해진 기간 동안만 보관 / 일반 로그는 버그나 오류 발생 시 몬제 해결을 위한 목적, 상황에 따라 제거

## 데이터 노출 줄이기

서비스 운영자는 다양한 고객의 정보를 조회할 수 있음 → 민감 정보를 마음만 먹으면 쉽게 탈취할 수 있음

- 마스킹 → 전화번호나 주소 일부를 마스킹 해 전달 → 클라이언트에서 마스킹 X, 서버에서 전달할 때 마스킹 처리
- 소수 인원에게만 고객 목록 조회 권한 부여 → 권한이 없는 사용자는 고객을 통해서만 정보 조회

자동화에 익숙한 경우 도구를 사용해 수집 가능 → 이상 접근을 빠르게 감지해 피해 최소화 (갑자기 고객 목록을 여러번 조회, 짧은 시간 간격으로 조회 …)

로그 메시지에 민감한 정보를 포함하지 않도록 주의 (트위터 케이스)

## 비정상 접근 처리

사용자가 평소와 다른 패턴을 보일 시 비정상 접근으로 판단하고 사용자에게 해당 내용을 알려주는 방식

- 평소와 다른 장소에서 로그인
- 평소와 다른 기기에서 로그인
- 로그인에 여러 차례 실패 → 연속 적으로 로그인에 실패하면 일시적으로 계정 정지 (브루트 포스 공격에 대응)
- 동일한 URL이나 API를 반복해서 접근
- 권한이 없는 URL이나 API에 대해 접근 시도 → 보통 사용자가 접근 가능한 기능만 노출하기 때문에

** 브루트 포스 공격 → 특정한 암호를 풀기 위해 가능한 모든 값을 대입하는 것

## 시큐어 코딩

```sql
String id = request.getParameter("id");
String query = "select id, name from member where id = '" + id + "'";
ResultSet rs = stmt.excuteQuery(query);
```

`abcd` 입력시 → select id, name from member where id = ‘abcd’

`‘ or 1=1 or id = ‘` 입력 시 → select id, name from member where id = ‘’ or 1=1 or id = ‘’

→ or로 연결되어 있고 항상 참인 1=1 조건이 있어 member 테이블의 모든 id와 name 탈취 가능 → SQL 인젝션 공격

Prepared Statement 사용 → 값에 포함된 특수 문자를 알맞게 변환해 SQL 생성

- 입력 값 검증 → 길이, 필수 여부, 미허용 값 등 검증
- 개인 정보/민감 정보 암호화 → 로그인 암호, 바이오 정보와 같이 인증에 사용되는 정보 뿐만이 아니라 주민 번호, 운전 면허 번호 같은 고유 식별 정보도 암호화
- 에러 메시지에 시스템 정보 노출 X
- 보안 통신 → HTTPS처럼 데이터를 암호화
- CORS 설정 → 허용된 도메인에서만 서버 자원에 접근할 수 있도록 제한
- CSRF 대응 → 타 사이트에서 위조 공격이 들어오는 것을 방지하기 해 CSRF 토큰, SameStie 쿠키, 캡차 등 사용

** CSRF → 사용자가 로그인된 상태에서 악성 사이트가 사용자의 권한으로 요청을 발생시키는 공격 → CSRF 토큰 (서버가 생성한 난수 토큰을 폼에 포함시키고 요청 시 검증)

** SameSite 쿠키 → 브라우저가 크로스사이트 요청에 쿠키를 자동 전송하지 않도록 설정 (Strict > Lax > None)

** 캡차 → 브루트 포스, 스크래핑, 봇 활동 탐지/차단을 위해 자동화된 악성 요청 방지

## 개인 보안

개발자 자체가 보안에 민감해야 함

- 물리적 보안 → 자리를 비울 경우 화면 보호기 실행, 중요 사이트 로그인 상태로 자리 비우지 않기 …

보안 수준을 높일 수록 비용이 증가해 스타트업에서는 보안 투자가 쉽지 않음 → 최소한의 인증과 인가에 신경쓰고 주요 정보를 암호화하여 서버 수준 방화벽 설정만으로도 보안 사고 발생 확률을 낮춤

# [서버 지식] 최소한 알아야 할 서버지식

규모가 큰 회사인 경우 인프라 / 플랫폼 담당팀과 서비스 개발팀으로 분리 → OS 설치나 설정, 관리에 대한 경험을 못 할 수도 있음

** VirtualBox, Vagrant 를 통해 OS 설치부터 다양한 설정까지 쉽게 할 수 있음

## OS 계정과 권한

서버 프로그램 프로세스 종료 후 재실행 했을 때 프로세스가 구동되지 않음 → root 계정으로 구동했다가 이후 일반 계정으로 구동해 root 계정으로 생성한 파일의 수정 권한 X

root 계정은 OS 설치 시 기본으로 생성되는 모든 권한을 가진 관리자 계정 (모든 권한이 허용되어 있어 root 계정은 접근 인원의 제한을 둠)

리눅스의 경우 여러 계정을 하나의 그룹으로 묶어 권한을 관리하기도 함

특정 파일을 실행했을 때 접근 거부 메시지를 받는다면 현재 사용 중인 계정에 권한이 없는 것

```bash
ls -l # 파일 권한을 포함한 정보 확인
chmod <권한> <파일> # 파일에 대한 권한 변경

```

### 파일 권한 표현

`<소유자 권한><그룹 권한><다른 계정 권한>`

- 소유자 - u / 그룹 - g / 다른 계정 - o / 전체 - a
- 추가 - + / 제거 - - / 지정 - =
- r : 읽기 → 4 / w : 쓰기 → 2 / x : 실행 → 1

→ [main.py](http://main.py) 파일에 소유자는 전체 권한을, 그룹은 실행 권한을, 다른 계정에는 아무 권한을 주고 싶지 않다면 `chmod rwx--x--- main.py`/`chmod 710 main.py` 로 설정 가능

→ [main.py](http://main.py) 파일의 다른 계정에 읽기 권한을 추가한다면 `chmod o+r main.py` 로 추가 가능

** 습관적으로 권한을 777로 주는 것은 지양, 필요한 만큼만 권한 부여

** 일반 사용자 계정으로 실행해야 하는 프로그램을 root 계정으로 실행하게 되면 이후 권한 문제 발생 가능 → root로 프로그램 실행 시 확인 필요

### sudo

인프라 담당자만 root 계정을 가지고 개발자는 일반 계정, 개발자가 루트 권한이 필요할 때마다 인프라 개발자에게 작업 요청하는 것은 번거롭지만 root를 주기엔 위험

→ sudo 명령어를 통해 다른 사용자의 권한으로 프로그램을 실행할 수 있음 (일반 사용자 → root 사용자)

```bash
/etc/sudoers 파일

root ALL=(ALL) ALL # 'root 계정은 모든 호스트에 대해 모든 사용자로 모든 명령어를 실행할 수 있다'의 의미
user1 ALL=(ALL) ALL # 만약 자신의 계정에 sudo로 모든 명령어를 실행할 수 있는 권한을 부여하고 싶다면 다음과 같이 설정
user2 ALL=(ALL) ALL NOPASSWD: ALL # sudo 실행시 비밀번호 제외하려면 NOPASSWD 설정, 특정 명령어에서만 비밀번호를 제외한다면 NOPASSWD: <특정명령어> 설정

visudo # sudo 파일 수정 명령어
```

** 파일을 제거하겠다고 `rm - rf` 명령어 사용 (파일 삭제) 시 현재 디렉토리 위치, 삭제 대상 파일 확인이 필요 

## 프로세스 확인

클라이언트에서 서버 연결이 안된다면 프로세스가 정상 실행 중인지 확인 필요 (재시작 해야하는데 이전 프로세스 남아있거나 시작하는 과정에서 오류 발생 등)

### 프로세스 확인 명령어

```bash
ps aux 
ps -eaf # 프로세스 ID 확인
htop # 프로세스가 사용하는 CPU나 메모리 사용량 실시간 확인
ps aux --sort -rss | head -n 6 메모리 사용량이 높은 상위 프로세스를 확인
```

### 프로세스 종료 명령어

```bash
kill <옵션> <프로세스 ID>
```

**옵션**

- -15 / -s SIGTERM / -TERM → 프로세스에 TERM 신호를 보내 종료에 필요한 작업 수행 (생성 파일 제거, 스프링의 경우 빈 제거)
- -9 / -s SIKILL / -KILL → 프로세스 강제 종료 (-15 옵션으로 계속 보내도 프로세스가 안 죽는다면 강제 종료)

## 백그라운드 프로세스

vi, top과 같이 서버에 접속해 터미널에서 실행하는 프로그램은 포그라운드 프로세스 → 터미널에 연결되어 키보드나 스크린을 통해 상호작용, 사용자와 터미널의 연결이 끊기면 종료

톰캣과 같이 항상 실행되어 있어야하는 프로세스는 백그라운드 프로세스 → 터미널과 연결되어 있지 않아 키보드나 스크린을 통해 상호작용 X

리눅스 기준 프로세스를 백그라운드에서 실행시키기 위해서 명령어 뒤에 `&` 추가, 터미널을 종료해도 실행되게 하려면 `nohup`과 `&` 사용

```bash
$ java -Dserver.port=8080 -jar server.jar &
$ nohup java -Dserver.port=8080 -jar server.jar > server.log 2>&1 & # 프로세스가 콘솔에 출력하는 메시지를 server.log 파일에 기록
```

** 터미널 → 오래전 메인프레임이라 불리는 컴퓨터에 연결할 때 사용자가 원격으로 접속하는 통로

** nohup → No Hang Up을 의미, 터미널 연결이 끊길 때 전송되는 HUP 시그널이 프로세스로 전달되지 않게 함

** 2>&1 → `2` (표준 오류) `>` (리디렉션) `&1` (표준 출력) → 표준 오류를 표준 출력과 동일한 경로로 전달하라는 의미

## 디스크 용량 관리

디스크 용량이 부족해 아무 작업도 할 수 없는 상태 → 재부팅을 해도 정상화되지 않아 OS 새로 설치

→ 서버 모니터링 도구를 사용해 일정 이상 시 알림 기능을 통해 파일 삭제 등의 조치 필요

```bash
df -h # 현재 디스크 사용량 -h는 용량을 바이트 단위가 아닌 MB나 GB로 출력
du -sh ./* # 어떤 디렉토리가 많은 용량을 차지하는 지 확인, du는 disk usage, -s는 하위 디렉토리 용량 합
```

**디스크 용량과 관련된 파일**

- 로그 파일 → 문제 발생 시 원인 분석을 위해 로그 수집 → 디스크에 로그가 쌓임 ⇒ 오래된 로그 제거, 별도 저장소에 로그 백업 후 삭제, 로그 압축 등의 방식으로 해결
- 파일 저장 (임시 파일 등) → 클라이언트가 전송한 파일을 임시로 보관한 뒤 파일 서버로 업로드 → 디스크에 임시 파일을 남김 → 일정 시간이 지나면 삭제하는 방식으로 해결

한 디렉토리에 너무 많은 파일이 저장되면 파일 탐색 속도가 저하됨 → 일정 개수 이하로 제한, 일자나 시간을 기준으로 폴더를 생성 `/2025/10/23` 

** `find ./logs -mtime +29 -type f -delete` → 30일 이전 파일 삭제하는 명령어 

** 로그 파일이 너무 커져 복사도 압축도 부담이라면 `cp /dev/null out.log` 명령어 사용 가능 → out.log에 있던 데이터들은 지워지지만 파일을 비울 수 있음 (급한 조치를 위해 사용)

## 파일 디스크립터 제한

프로세스에서 데이터 입출력이 필요한 경우 OS로부터 파일 디스크립터를 할당 받음 → OS에서는 디스크립트의 생성 개수를 제한, 따라서 트래픽이 몰릴 경우 생성에 실패

→ 트래픽 증가에 맞춰 미리 파일 디스크립터 개수 제한을 확인하고 증가시켜야 함

```bash
ulimit -a # 파일 디스크립터 개수 제한 확인 -> open files의 값이 디스크립터 개수 제한
ulimit -n <개수> # 디스크립터 개수 제한 변경 -> 세션을 기준으로 적용되므로 로그아웃하고 다시 접속 필요

/etc/security/limits.conf 파일 # 기본 파일 디스크립터 제한 변경
* soft nofile 10000 
* hard nofile 10000 # 모든 사용자에 대해 디스크립터 제한 변경, soft는 기본값, hard는 최대값

systemd로 실행되는 파일의 경우
systemctl show -p DefaultLimitNOFILE # systemd로 실행되는 서비스의 기본 파일 디스크립터 제한

/etc/systemd/system.conf
DefaultLimitNOFILe=10000 # systemd로 실행되는 경우 /etc/security/limits.conf 설정 값을 보지 않아 /etc/systemd/system.conf 수정 필요
systemctl daemon-reload # /etc/systemd/system.conf 변경 내용 적용

각 서비스마다 파일 디스크립터 설정 시 
/etc/systemd/system 또는 /usr/lib/systemd/system 디렉토리의 개별 서비스 설정 파일에
LimitNOFILE=10000 

sysctl fs.nr_open # 한 프로세스가 가질 수 있는 파일 디스크립터 개수 확인 명령어
sysctl fs.file--max # 시스템 전체의 파일 디스크립터 개수 확인 명령어

/etc/sysctl.conf 파일
fs.nr_open=100000 # 한 프로세스가 가질 수 있는 프로세스 개수 변경 명령어
fs.file-max=100000 # 시스템 전체의 최대 파일 디스크립터 개수 변경 명령어
sysctl -p # 변경사항 적용

cat /porc/<프로세스 ID>/limits # 프로세스의 파일 디스크립터 제한 값 확인

lsof -p <프로세스 ID>  # 프로세스가 사용 중인 파일 디스크립터 개수 확인
lsof -p <프로세스 ID> | wc -l
```

** systemd → 리눅스의 시스템 초기화(부팅) 및 서비스 관리 도구

## 시간 맞추기

서버 운영 시 시간 동기화 중요 → 컴퓨터가 관리하는 시간과 실제 세계의 시간은 조금씩 오차가 있고 누적되다 보면 수 초 이상 차이가 날 수 있음

서버 간 시간이 30초 이상 차이 나 결제가 승인이 안되는 케이스 경험

→ chrony나 ntp 같은 서비스를 이용해 주기적으로 서버 시간을 맞추는 작업 필요

## 크론으로 스케줄링하기

서버를 운영하다보면 매일 n시에 로그 파일 삭제, n시 n분에 로그 압축 등 일정 시간마다 해야할 일 존재

→ 유닉스 계열의 OS의 시간 기반 스케줄러

```bash
crontab -l # 크론탭에 정의된 작업 목록 조회
0 1 * * * /data/proejct/run-db-job.sh # 매일 1시에 /data/project/run-db-job.sh 실행
```

`분 시 일 월 요일` 형식

- `*` - 매 시간을 의미
- `,` - 개별 값 `0 1,2,3 * * *` → 매일 1시, 2시, 3시에 실행
- `-` - 구간 지정 `0 1-3 * * *` → 매일 1시부터 3시에 실행
- `/` - 시간 간격 지정 `0 */10 * * *` → 매일 10분 간격으로 실행

** 일회성 작업의 경우 cron이 아닌 at 명령어 사용

## alias 등록하기

자주 사용하는 명령어를 별칭으로 지정

```bash
alias cdweb='cd /var/www/html' # 현재 터미널 세션에만 적용

~/.bashrc 파일
# alias
alias cdweb='cd /var/www/html' # .bashrc 파일에 alias 설정을 추가하면 로그인할 때마다 alias가 적용됨
```

## 네트워크 정보 확인

### IP 정보 확인

ifconfig 명령어를 통해 확인할 수 있음

```bash
ifconfig
	inet # IPv4 주소 
	inet6 # IPv6 주소
	ether # MAC 주소
	RX # 수신된 패킷 수와 바이트 크기
	TX # 전송한 패킷 수와 바이트 크기
```

### nc 명령어로 연결 확인

```bash
nc -z -v www.daum.net 443 # 443 포트로 www.daum.net에 연결이 되는지 확인, -z 옵션은 데이터 전송없이 포트가 열려있는지만 확인, -v 옵션은 추가 정보 출력
nc -u -z -v localhost 6100 # UDP 포트의 경우 -u 옵션 사용 
nc -l -v -p 1234 # 로컬 서버에서 지정한 포트(1234)를 열고 클라이언트 요청을 대기하는 명령
```

** 외부 서버로 API 실행 시 curl이나 wget 사용

### netstat 명령어로 포트 사용 확인

```bash
netstat -lputn # 현재 서버에서 열려있는 포트 확인
netstat -anp | grep 12931 # 현재 사용중인 포트 확인 // grep은 텍스트 검색 도구

# -l -> 리스닝 서버 소켓 출력
# -p -> 소켓을 사용하는 PID/프로그램 이름 출력
# -u -> UDP 소켓 출력
# -t -> TCP 소켓 출력
# -n -> 포트나 주소를 숫자로 출력
```

** 해당 포트가 사용 중이라는 에러가 발생할 시 netstat으로 포트 상태 확인

# [네트워크 기초]

서버 개발자가 네트워크 엔지니어만큼 깊게 알 필요는 없지만 관련 이슈 발생 시 처리할 정도의 기초 지식은 필요

## 노드, 네트워크, 라우터

노드 → 데이터를 송수신하는 모든 장치 (휴대폰, 노트북, 서버 장비 등)

네트워크 → 노드가 서로 데이터를 주고받기 위해 연결된 시스템

라우터 → 네트워크 간 패킷을 전송하는 역할

```bash
휴대폰 → 라우터 → 라우터 → 라우터 → 서버 (목적지)
```

** 패킷 → 네트워크를 통해 전송하는 데이터의 단위 (헤더 + 페이로드) 

## IP 주소와 도메인

IP 주소 → 네트워크에서 각 노드를 구분하기 위해 사용하는 주소

도메인 → IP 주소에 기억하기 쉬운 이름 부여 (도메인 이름과 IP 주소로 변환하는 체계를 DNS)

** IPv6 → IPv4 주소의 고갈로 더 많은 노드에 고유한 주소를 부여할 수 있는 새로운 주소

도메인은 계층 구조를 가짐 → 오른쪽이 최상위 계층, 각 계층마다 `.`으로 `구분`

[`cafe.naver.com`](http://cafe.naver.com) → 1차 도메인 com, 2차 도메인 naver (도메인의 주요 이름), 3차 도메인 cafe (용도에 맞는 이름)

```bash
웹 브라우저 → DNS를 통해 해당 도메인의 IP 주소 확인 → 받은 IP 주소를 기반으로 요청 패킷 전달 → 응답
```

로컬에서 사용하는 [localhost](http://localhost) 주소는 루프백 주소로 자기 자신을 참조할 때 사용

** hosts 파일 → 호스트 이름과 IP 주소에 대한 매핑 확인 가능

** `nslookup <도메인>` → 도메인 이름에 매핑되는 여러 개의 IP 주소 반환

** 루프백 주소 → **자기 자신을 가리키는 IP 주소** (네트워크를 실제로 거치지 않고 내부 네트워크 스택을 테스트할 때 사용)

## 고정 IP와 동적 IP

동일 네트워크 상에서 존재하는 각 노드는 서로 다른 IP 주소를 가져야 함, 같은 IP 주소가 존재할 경우 충돌 발생

고정 IP → 노드가 고정된 IP를 가짐 (서버 IP와 같이 바뀌지 않는 IP 주소)

동적 IP → 네트워크에 연결할 때마다 IP 할당, DHCP 서버를 통해 제공 (가정용 공유기 ..)

** DHCP → **IP 주소를 자동으로 할당해주는 서버, 네트워크에 연결된 노드가 수동 설정하지 않아도 되게 도와줌**

1. Discover - 클라이언트가 IP 요청 브로드캐스트로 전송
2. Offer - DHCP 서버가 사용 가능한 IP주소 제안
3. Request - 클라이언트에서 제안된 IP를 요청
4. Acknowledge - 서버가 해당 IP 사용을 승인하고 설정

## 공인 IP와 사설 IP

공인 IP → 인터넷에서 접근 가능한 IP 주소 (웹브라우저 접속 시 DNS로부터 받은 IP 주소로 접속하는 방식, 어느 네트워크에서든 접근 가능)

사설 IP → 네트워크 내부에만 적용되는 IP 주소 (네트워크에 속한 노드에 할당되는 주소로 네트워크 외부에서는 접근 불가)

** 공인 IP는 같은 IP 주소를 가질 수 없지만, 사설 IP는 네트워크가 다르면 같은 IP 주소를 사용할 수 있음

사설 IP 허용 범위

- `192.168.*.*`
- `10.*.*.*`
- `172.16.*.* ~ 172.31.*.*`

ifconfig나 ipconfig 명령어를 통해 사용중인 노트북의 IP 주소를 확인할 수 있음 

공인 IP는 인터넷에서 서비스를 제공하는 경우 사용 → 사설 IP를 통해 공인 IPv4 주소를 현재까지 사용할 수 있음

## NAT

내부에서 사용하는 사설 IP와 인터넷에서 사용하는 공인 IP 주소간 변환을 담당 → 라우터와 같은 네트워크 장비 담당

- SNAT → 소스 사설 IP를 공인 IP로 변환 `휴대폰 → 192.168.1.10 → SNAT → 218.39.*.* 변환 → 인터넷`
- DNAT → 목적지 공인 IP를 사설 IP로 변환 `휴대폰 → 58.221.*.* → DNAT → 10.1.1.101 변환 → 서버 노드`
    
    보통 서버 구성에 사용 → 네트워크 구성 시 보안, 이중화 등을 고려해 사설 IP주소를 가짐
    
    공인 IP 주소는 네트워크 연결을 관리하는 장비에 할당
    
    DNAT을 이용해 공인 IP로 들어온 패킷을 사설 IP를 가진 서버 노드에 전송
    

## VPN

서버 네트워크에 존재하는 노드는 사설 IP 사용 → 일일이 NAT으로 변환할 수 있지만 노드 개수가 많은 경우 불가능, 하더라도 모든 노드가 공인 IP로 노출

→ 공용 네트워크에서 서로 다른 네트워크 간의 암호화된 연결 제공, 두 네트워크를 마치 하나의 사설 네트워크인 것처럼 연결

```
개발자 → VPN 장비 --- 통신 암호화 --- VPN 장비 → 서버 1
																							 → 서버 2
																							 → 서버 3
	 사무실 네트워크                      서버 네트워크																
```

## 프로토콜과 TCP, UDP, QUIC

프로토콜 → 네트워크 상에서 두 노드가 데이터를 주고받기 위해 정의한 규칙

**TCP/IP 4계층**

- 물리
- 데이터 링크
- 네트워크 → IP
- 전송 → TCP / UCP
- 응용 → HTTP / FTP / SMTP

### TCP

연결 기반 프로토콜, 연결을 위해 3-Way Handshake 과정을 거침 (SYN → ACK + SYN → ACK) → HTTP, SMTP 등에서 사용

장점 → 패킷의 순서를 보장하고 패킷이 유실된 경우 재전송 하는 기능을 제공해 안정적인 전송이 가능

단점 → 전송 속도는 UDP에 비해 느리고, 일부 패킷 유실 시 해당 패킷 도착까지 다른 패킷을 제대로 처리하지 못하는 HOL 블로킹 문제 발생 가능

### UDP

비연결형 프로토콜, 연결 과정 없이 바로 데이터 전송 → DNS, VOIP, 게임 등에서 사용

장점 → 응답 확인이나 패킷 정렬과 같은 과정을 거치지 않아 전송 속도가 빠름

단점 → 응답 확인이나 패킷 정렬과 같은 과정을 거치지 않아 안정성이 떨어짐 

### QUIC

UDP를 기반으로 TCP의 연결 관리 기능을 프로토콜 수준에서 제공하는 프로토콜 → 연결 ID를 포함해 노드간 연결 제어, 혼잡 제어, 패킷 유실 복구 기능 등 제공

→ TLS를 통합 (TCP+TLS는 2번의 핸드셰이크로 레이턴시가 크지만 연결수립과 동시에 TLS 설정), 패킷을 암호화 해 전송

- 멀티플렉싱 지원 → 한 연결에서 여러 스트림을 동시에 처리 가능 → 하나의 스트림에서 HOL 블로킹이 발생해도 다른 스트림에 영향을 주지 않음

** HTTP/3에서는 QUIC 지원

** TCP는 이론적으로 2^96 개의 연결을 생성할 수 있지만, 실제로는 OS 설정(파일 디스크립터, 포트 범위 설정 …)에 따라 제약을 받음

# [자주 쓰이는 디자인 패턴]

## MVC 패턴

- MODLE → 비지니스 영역의 로직 처리
- VIEW → 사용자가 보게 될 결과 화면 생성, 로직이나 흐름 제어와 관계 없이 보여질 화면만 제공하면됨
- CONTROLLER → 사용자의 입력 처리와 흐름 제어 담당, 요청을 해석해 알맞은 모델을 실행하고 뷰만 선택

`User → Controller → Model → View → Controller → User`

**핵심**

- 비지니스 로직을 처리하는 모델과 결과를 생성하는 뷰 분리
- 애플리케이션 흐름 제어나 사용자 요청 처리는 컨트롤러에 집중

각 요소들은 분리되어 있어 의존성이 낮음 → 유지보수 용이

## 계층형 아키텍처

각 계층마다 특정 역할을 수행하고 하위에 위치한 계층에만 의존, 하위 계층은 상위 계층에 의존하지 앟음

- 표현 (UI) → 사용자와의 상호 작용
- 응용 → 요청을 실제로 처리
- 도메인 → 도메인 로직 구현 (주문 취소나 상태 변경 등 로직)
- 인프라 → DB 연동이나 문자 발송과 같은 구현 기술 지원

→ 도메인 구현에 미숙한 경우 도메인 영역이 인프라와 응용 계층으로 분산되면서 코드 유지가 어려워지기도 함

## DDD와 전술 패턴

DDD 도메인 모델 구성 요소

- 엔티티 → 고유한 식별자를 가지며 내부 값이 바뀌어도 식별자는 바뀌지 않음
- 벨류 → 고유의 식별자를 가지지 않으며 개념적인 값 표현, 값은 불변으로 묶는 것을 지향
- 에그리거트 → 관련된 객체를 묶어 하나의 개념 단위 표현, 모델의 일관성을 관리하는 단위
- 리포지토리 → 도메인 객체를 물리적인 저장소와 연결할 때 사용하는 모델
- 도메인 서비스 → 특정한 애그리거트에 속하지 않은 로직 구현
- 도메인 이벤트 → 도메인 내에서 발생한 이벤트 표현

→ DDD는 도메인 로직을 애그리거트 단위로 묶음 → 복잡한 모델을 애그리거트 단위로 관리해 복잡도를 낮추고, 로직의 응집도를 높여 유지보수성을 높임

- 엔티티 간 참조는 Aggregate Root를 통해서만 접근해야 함
- Repository는 Aggregate 단위로 존재해야 함
- DDD → **복잡한 도메인 로직을 명확히 분리하고, 변경 영향을 최소화**

## 마이크로 서비스 아키텍처

서비스를 작은 단위로 분리하고 각 서비스가 연동되는 구조를 가지는 패턴

|  | 모놀리식 | 마이크로서비스 |
| --- | --- | --- |
| 장점 | - 배포가 단순
- 코드 관리가 쉬움
- 성능을 높이기 위해 복잡한 구조를 가질 필요가 없음
- 테스트와 디버깅이 쉬움 | - 독립적인 배포와 지속적인 배포가 용이
- 성능 확장 용이
- 기술에 대한 유연성
  |
| 단점 | - 규모가 커질 수록 개발 속도 감소
- 한 기능의 문제가 전체의 문제
- 구현 기술 변경에 어려움
- 작은 변경도 전체 배포로 이어짐 | - 테스트와 디버깅이 어려움
- 인프라가 복잡해짐
- 소통에 따른 부하 증가
- 무분별하게 서비르르 반들면 분산 모놀리식이 됨 |

핵심 개념 - 독립적 배포, 도메인 중심 모델링, 자신의 상태를 가짐 (DB 공유 X), 크기, 유연, 아키텍처와 조직을 맞춤

→ 이중 독립적 배포가 가장 중요 → 각 마이크로서비스 간 결합도를 최소한으로 설정

## 이벤트 기반 아키텍처

과거에 발생한 사실을 기반으로 두 시스템 간의 통신이 이루어지는 패턴

- 이벤트 생산자
- 이벤트 소비자
- 이벤트 브로커 (라우터)

→ 이벤트 생산자는 이벤트를 생성해 브로커에게 전달, 브로커는 해당 이벤트를 구독중인 소비자에게 이벤트 전달

이벤트 기반 아키텍처는 메시지의 한 형태로 볼 수 있음

장점 → 생산자와 소비자가 직접 연결되지 않고 브로커를 통해 연결되어 서로 간섭하지 않고 독립적으로 배포가 가능, 새로운 소비자 추가가 용이

단점 → 이벤트가 중간 브로커를 거치기 때문에 이벤트 처리 상태를 추적하기 위해 별도의 추가 수단 필요

** 메시지 설계나 처리시 고려사항은 5장의 내용과 동일

## CQRS 패턴

명령 (상태변경)을 위한 모델과 조회를 위한 모델 분리

장점 → 각 기능에 맞게 모델 구현해 상호 영향 문제 최소화, 조회 모델이 별도로 존재해 조회 성능 향상이 쉬움

단점 → 각 기능마다 모델을 따로 만들어야 해 코드가 증가, 명령 모델과 조회 모델을 다른 기술로 구현 시 두 DB간 데이터 동기화를 위해 추가적인 메시징 수단 도입 필요

** 단순한 모델의 경우 CQRS 적용 시 작업량만 증가할 수 있음, 복잡한 경우 CQRS 적용으로 인한 이점이 클 가능성이 높음
